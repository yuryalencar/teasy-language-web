@inproceedings{10.1145/2072221.2072247,
author = {Solms, Fritz and Edwards, Craig and Paar, Alexander and Gruner, Stefan},
title = {A Domain-Specific Language for URDAD Based Requirements Elicitation},
year = {2011},
isbn = {9781450308786},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2072221.2072247},
doi = {10.1145/2072221.2072247},
abstract = {Use-Case Responsibility-Driven Analysis and Design (URDAD) is a service-oriented software analysis and design methodology. It is used by requirements engineers to develop technology-neutral, semi-formal platform-independent models (PIM) within the OMG's MDA. In the past, URDAD models were denoted in UML. However, that was tedious and error-prone. The resulting models were often of rather poor quality. In this paper we introduce and discuss a new Domain-Specific Language (DSL) for URDAD. Its meta model is consistent and satisfiable. We show that URDAD DSL specifications are simpler and allow for more complete service contract specifications than their corresponding UML expressions. They also enable traceability and test case generation.},
booktitle = {Proceedings of the South African Institute of Computer Scientists and Information Technologists Conference on Knowledge, Innovation and Leadership in a Diverse, Multidisciplinary Environment},
pages = {224–230},
numpages = {7},
keywords = {service orientation, model driven development, platform independent model, domain specific language, requirements engineering, meta model},
location = {Cape Town, South Africa},
series = {SAICSIT '11}
}

@inproceedings{10.1145/2915970.2916010,
author = {H\"{a}ser, Florian and Felderer, Michael and Breu, Ruth},
title = {An Integrated Tool Environment for Experimentation in Domain Specific Language Engineering},
year = {2016},
isbn = {9781450336918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2915970.2916010},
doi = {10.1145/2915970.2916010},
abstract = {Domain specific languages (DSLs) are widely used in practice and investigated in software engineering research. But so far, language workbenches do not provide sufficient built-in decision support for language design and improvement. Controlled experiments have the potential to provide appropriate, data-driven decision support for language engineers and researchers to compare different language features with evidence-based feedback. This paper provides an integrated end-to-end tool environment to perform controlled experiments in DSL engineering. The experiment environment is built on the basis and integrated into the language workbench Meta Programming System (MPS). The environment not only supports language design but also all steps of experimentation, i.e., planning, operation, analysis &amp; interpretation, as well as presentation &amp; package. The tool environment is presented by means of a running example experiment comparing the time taken to create system acceptance tests for web applications in two different DSLs.},
booktitle = {Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering},
articleno = {20},
numpages = {5},
keywords = {tool support, empirical evaluation, domain specific languages (DSLs), meta programming system (MPS), controlled experiment, language engineering, experimentation},
location = {Limerick, Ireland},
series = {EASE '16}
}

@inproceedings{10.1145/2851613.2851749,
author = {Mohr, David and Stefanovic, Darko},
title = {Stella: A Python-Based Domain-Specific Language for Simulations},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2851749},
doi = {10.1145/2851613.2851749},
abstract = {We wish to make it easier and quicker to write well-performing scientific simulations that (1) have single-thread performance competitive with low-level languages, (2) use object-oriented programming to properly structure the code, and (3) are very easy to develop. Instead of prototyping in a high-level language and then rewriting in a lower-level language, we created a DSL embedded in Python that is transparently usable, retains some OOP features, compiles to machine code, and executes at speed similar to C.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1952–1959},
numpages = {8},
keywords = {Python, domain-specific languages, scientific simulations},
location = {Pisa, Italy},
series = {SAC '16}
}

@article{10.1007/s00165-016-0359-1,
author = {Keshishzadeh, Sarmen and Mooij, Arjan J.},
title = {Formalizing and Testing the Consistency of DSL Transformations},
year = {2016},
issue_date = {Apr 2016},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {28},
number = {2},
issn = {0934-5043},
url = {https://doi.org/10.1007/s00165-016-0359-1},
doi = {10.1007/s00165-016-0359-1},
abstract = {A domain specific language (DSL) focuses on the essential concepts in a specific problem domain, and abstracts from low-level implementation details. The development of DSLs usually centers around the meta-model, grammar and code generator, possibly extended with transformations to analysis models. Typically, little attention is given to the formal semantics of the language, whereas this is essential for reasoning about DSL models, and for assessing the correctness of the generated code and analysis models. We argue that the semantics of a DSL should be defined explicitly and independently of any code generator, to avoid all kinds of complexities from low-level implementation details. As the generated analysis models must reflect some of these implementation details, we propose to formalize them separately. To assess the correctness and consistency of the generated code and analysis models in a practical way, we use conformance testing. We extensively illustrate this general approach using specific formalizations for an industrial DSL on collision prevention. We do not aim for a generic semantic model for any DSL, but this specific DSL indicates the potential of a modular semantics to facilitate reuse among DSLs.},
journal = {Form. Asp. Comput.},
month = {apr},
pages = {181–206},
numpages = {26},
keywords = {Semantics, Domain specific language (DSL), Conformance testing, Code generation}
}

@inproceedings{10.1145/3510457.3513078,
author = {Elsner, Daniel and Wuersching, Roland and Schnappinger, Markus and Pretschner, Alexander and Graber, Maria and Dammer, Ren\'{e} and Reimer, Silke},
title = {Build System Aware Multi-Language Regression Test Selection in Continuous Integration},
year = {2022},
isbn = {9781450392266},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510457.3513078},
doi = {10.1145/3510457.3513078},
abstract = {At IVU Traffic Technologies, continuous integration (CI) pipelines build, analyze, and test the code for inadvertent effects before pull requests are merged. However, compiling the entire code base and executing all regression tests for each pull request is infeasible due to prohibitively long feedback times. Regression test selection (RTS) aims to reduce the testing effort. Yet, existing safe RTS techniques are not suitable, as they largely rely on language-specific program analysis. The IVU code base consists of more than 13 million lines of code in Java or C/C++ and contains thousands of non-code artifacts. Regression tests commonly operate across languages, using cross-language links, or read from non-code artifacts. In this paper, we describe our build system aware multi-language RTS approach, which selectively compiles and executes affected code modules and regression tests, respectively, for a pull request. We evaluate our RTS technique on 397 pull requests, covering roughly 2,700 commits. The results show that we are able to safely exclude up to 75% of tests on average (no undetected real failures slip into the target branches) and thereby save 72% of testing time, whereas end-to-end CI pipeline time is reduced by up to 63% on average.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
pages = {87–96},
numpages = {10},
keywords = {software testing, continuous integration, regression test selection},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIP '22}
}

@inproceedings{10.1145/3460319.3464834,
author = {Elsner, Daniel and Hauer, Florian and Pretschner, Alexander and Reimer, Silke},
title = {Empirically Evaluating Readily Available Information for Regression Test Optimization in Continuous Integration},
year = {2021},
isbn = {9781450384599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3460319.3464834},
doi = {10.1145/3460319.3464834},
abstract = {Regression test selection (RTS) and prioritization (RTP) techniques aim to reduce testing efforts and developer feedback time after a change to the code base. Using various information sources, including test traces, build dependencies, version control data, and test histories, they have been shown to be effective. However, not all of these sources are guaranteed to be available and accessible for arbitrary continuous integration (CI) environments. In contrast, metadata from version control systems (VCSs) and CI systems are readily available and inexpensive. Yet, corresponding RTP and RTS techniques are scattered across research and often only evaluated on synthetic faults or in a specific industrial context. It is cumbersome for practitioners to identify insights that apply to their context, let alone to calibrate associated parameters for maximum cost-effectiveness. This paper consolidates existing work on RTP and unsafe RTS into an actionable methodology to build and evaluate such approaches that exclusively rely on CI and VCS metadata. To investigate how these approaches from prior research compare in heterogeneous settings, we apply the methodology in a large-scale empirical study on a set of 23 projects covering 37,000 CI logs and 76,000 VCS commits. We find that these approaches significantly outperform established RTP baselines and, while still triggering 90% of the failures, we show that practitioners can expect to save on average 84% of test execution time for unsafe RTS. We also find that it can be beneficial to limit training data, features from test history work better than change-based features, and, somewhat surprisingly, simple and well-known heuristics often outperform complex machine-learned models.},
booktitle = {Proceedings of the 30th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {491–504},
numpages = {14},
keywords = {software testing, regression test optimization, machine learning},
location = {Virtual, Denmark},
series = {ISSTA 2021}
}

@article{10.1145/2659118.2659136,
author = {Zhou, Jingang and Yin, Kun},
title = {Automated Web Testing Based on Textual-Visual UI Patterns: The UTF Approach},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {5},
issn = {0163-5948},
url = {https://doi.org/10.1145/2659118.2659136},
doi = {10.1145/2659118.2659136},
abstract = {Automated software testing is the only resort for delivering quality software, since there are usually large test suites to be executed, especially for regression testing. Though many automated testing tools and techniques have been developed, they still do not solve all problems like cost and maintenance, and they can even be brittle in some situations, thus confining their adoption. To address these issues, we develop a pattern-based automated testing framework, called UTF (User-oriented Testing Framework), for Web applications. UTF encodes textual-visual information about and relationships between widgets into a domain specific language for test scripts based on the underlying invariant structural patterns in the DOM, which allows test scripts to be easily created and maintained. In addition, UTF provides flexible extension and customization capabilities to make it adaptable for various Web-application scenarios. Our experiences show UTF can greatly reduce the cost of adopting automated testing and facilitate its institutionalization.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {sep},
pages = {1–6},
numpages = {6},
keywords = {user-interface pattern, domain-specific language, automated testing, web application}
}

@article{10.1145/1151695.1151697,
author = {Sinha, Avik and Smidts, Carol},
title = {HOTTest: A Model-Based Test Design Technique for Enhanced Testing of Domain-Specific Applications},
year = {2006},
issue_date = {July 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/1151695.1151697},
doi = {10.1145/1151695.1151697},
abstract = {Model-based testing is an effective black-box test generation technique for applications. Existing model-based testing techniques, however, fail to capture implicit domain-specific properties, as they overtly rely on software artifacts such as design documents, requirement specifications, etc., for completeness of the test model. This article presents a technique, HOTTest, which uses a strongly typed domain-specific language to model the system under test. This allows extraction of type-related system invariants, which can be related to various domain-specific properties of the application. Thus, using HOTTest, it is possible to automatically extract and embed domain-specific requirements into the test models. In this article we describe HOTTest, its principles and methodology, and how it is possible to relate domain-specific properties to specific type constraints. HOTTest is described using the example of HaskellDB, which is a Haskell-based embedded domain-specific language for relational databases. We present an example application of the technique and compare the results to some other commonly used Model-based test automation techniques like ASML-based testing, UML-based testing, and EFSM-based testing.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {jul},
pages = {242–278},
numpages = {37},
keywords = {Haskell, Test case generation, model-based testing, HaskellDB, database-specific test case generation, test generation tools, domain-specific languages, domain-specific testing}
}

@inproceedings{10.1145/3183895.3183897,
author = {Schuts, Mathijs and Hooman, Jozef and Tielemans, Paul},
title = {Industrial Experience with the Migration of Legacy Models Using a DSL},
year = {2018},
isbn = {9781450363556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183895.3183897},
doi = {10.1145/3183895.3183897},
abstract = {Software departments of companies that exist for several decades often have to deal with legacy models. Important business assets have been modelled with tools that are no longer preferred within the company. Manually remodelling these models with a new tool would be too costly. In this paper, we describe an approach to migrate from Rhapsody models to models of another tool. To perform the migration, we created a Domain Specific Language (DSL) that accepts Rhapsody models as instances. A generator of this DSL can then produces model instances for the new tool. To get confidence in the transformation in a pragmatic way, we applied a combination of model learning and equivalence checking. Learning has been applied to both the source code generated by Rhapsody and the code generated by the new tool. The resulting models are compared using equivalence checking.},
booktitle = {Proceedings of the Real World Domain Specific Languages Workshop 2018},
articleno = {1},
numpages = {10},
keywords = {Legacy, Model-based development, Domain specific languages, Model transformation, Tool migration},
location = {Vienna, Austria},
series = {RWDSL2018}
}

@inproceedings{10.1145/2422518.2422521,
author = {Sousa, Gustavo C. M. and Costa, F\'{a}bio M. and Clarke, Peter J. and Allen, Andrew A.},
title = {Model-Driven Development of DSML Execution Engines},
year = {2012},
isbn = {9781450318020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2422518.2422521},
doi = {10.1145/2422518.2422521},
abstract = {The combination of domain-specific modeling languages and model-driven engineering techniques hold the promise of a breakthrough in the way applications are developed. By raising the level of abstraction and specializing in building blocks that are familiar in a particular domain, it has the potential to turn domain experts into application developers. Applications are developed as models, which in turn are interpreted at runtime by a specialized execution engine in order to produce the intended behavior. This approach has been successfully applied in different domains, such as communication and smart grid management to execute applications described by models that can be created and changed at runtime. However, each time the approach has to be realized in a different domain, substantial re-implementation has to take place in order to put together an execution engine for the respective DSML. In this paper, we present our work towards a generalization of the approach in the form of a metamodel which captures the domain-independent aspects of runtime model interpretation and allow the definition of domain-specific execution engines.},
booktitle = {Proceedings of the 7th Workshop on Models@run.Time},
pages = {10–15},
numpages = {6},
keywords = {model-driven engineering, models@run.time, domain-specific modeling languages, metamodeling},
location = {Innsbruck, Austria},
series = {MRT '12}
}

@article{10.1145/2693208.2693226,
author = {Bokil, Prasad and Krishnan, Padmanabhan and Venkatesh, R.},
title = {Achieving Effective Test Suites for Reactive Systems Using Specification Mining and Test Suite Reduction Techniques},
year = {2015},
issue_date = {January 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/2693208.2693226},
doi = {10.1145/2693208.2693226},
abstract = {Failures in reactive embedded systems are often unacceptable. Moreover, effective testing of such systems to detect potential critical failures is a difficult task.We present an automated black box test suite generation technique for reactive systems. The technique is based on dynamic mining of specifications, in form of a finite state machine (FSM), from initial runs. The set of test cases thus produced contain several redundant test cases, many of which are eliminated by a simple greedy test suite reduction algorithm to give the final test suite. The effectiveness of tests generated by our technique was evaluated using five case studies from the reactive embedded domain. Results indicate that a test suite generated by our technique is promising in terms of effectiveness and scalability. While the test suite reduction algorithm removes redundant test cases, the change in effectiveness of test suites due to this reduction is examined in the experimentation.We present our specification mining based test suite generation technique, the test suite reduction technique and results on industrial case studies.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {feb},
pages = {1–8},
numpages = {8},
keywords = {test suite reduction, black box testing, specification mining}
}

@inproceedings{10.1145/2997364.2997382,
author = {Al-Sibahi, Ahmad Salim and Dimovski, Aleksandar S. and W\k{a}sowski, Andrzej},
title = {Symbolic Execution of High-Level Transformations},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2997364.2997382},
doi = {10.1145/2997364.2997382},
abstract = {Transformations form an important part of developing domain specific languages, where they are used to provide semantics for typing and evaluation. Yet, few solutions exist for verifying transformations written in expressive high-level transformation languages. We take a step towards that goal, by developing a general symbolic execution technique that handles programs written in these high-level transformation languages. We use logical constraints to describe structured symbolic values, including containment, acyclicity, simple unordered collections (sets) and to handle deep type-based querying of syntax hierarchies. We evaluate this symbolic execution technique on a collection of refactoring and model transformation programs, showing that the white-box test generation tool based on symbolic execution obtains better code coverage than a black box test generator for such programs in almost all tested cases.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {207–220},
numpages = {14},
keywords = {program transformation, model transformation, automated white-box test generation, symbolic execution},
location = {Amsterdam, Netherlands},
series = {SLE 2016}
}

@inproceedings{10.1145/3340433.3342825,
author = {Kessel, Marcus and Atkinson, Colin},
title = {A Platform for Diversity-Driven Test Amplification},
year = {2019},
isbn = {9781450368506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340433.3342825},
doi = {10.1145/3340433.3342825},
abstract = {Test amplification approaches take a manually written set of tests (input/output mappings) and enhance their effectiveness for some clearly defined engineering goal such as detecting faults. Conceptually, they can either achieve this in a ``black box'' way using only the initial ``seed'' tests or in a ``white box'' way utilizing additional inputs such as the source code or specification of the software under test. However, no fully black box approach to test amplification is currently available even though they can be used to enhance white box approaches. In this paper we introduce a new approach that uses the seed tests to search for existing redundant implementations of the software under test and leverages them as oracles in the generation and evaluation of new tests. The approach can therefore be used as a stand alone black box test amplification method or in tandem with other methods. In this paper we explain the approach, describe its synergies with other approaches and provide some evidence for its practical feasibility.},
booktitle = {Proceedings of the 10th ACM SIGSOFT International Workshop on Automating TEST Case Design, Selection, and Evaluation},
pages = {35–41},
numpages = {7},
keywords = {mining software repositories, oracle problem, automated testing, test amplification, behavior, observations},
location = {Tallinn, Estonia},
series = {A-TEST 2019}
}

@inproceedings{10.1145/3053600.3053636,
author = {Ferme, Vincenzo and Pautasso, Cesare},
title = {Towards Holistic Continuous Software Performance Assessment},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053636},
doi = {10.1145/3053600.3053636},
abstract = {In agile, fast and continuous development lifecycles, software performance analysis is fundamental to confidently release continuously improved software versions. Researchers and industry practitioners have identified the importance of integrating performance testing in agile development processes in a timely and efficient way. However, existing techniques are fragmented and not integrated taking into account the heterogeneous skills of the users developing polyglot distributed software, and their need to automate performance practices as they are integrated in the whole lifecycle without breaking its intrinsic velocity. In this paper we present our vision for holistic continuous software performance assessment, which is being implemented in the BenchFlow tool. BenchFlow enables performance testing and analysis practices to be pervasively integrated in continuous development lifecycle activities. Users can specify performance activities (e.g., standard performance tests) by relying on an expressive Domain Specific Language for objective-driven performance analysis. Collected performance knowledge can be thus reused to speed up performance activities throughout the entire process.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {159–164},
numpages = {6},
keywords = {continuous software performance assessment, performance analysis, continuous integration, performance test},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/2993236.2993257,
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
title = {Automated Regression Testing of BPMN 2.0 Processes: A Capture and Replay Framework for Continuous Delivery},
year = {2016},
isbn = {9781450344463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2993236.2993257},
doi = {10.1145/2993236.2993257},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture &amp; replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {178–189},
numpages = {12},
keywords = {BPMN 2.0, jBPM, Performance Overhead, Business Process Execution, Regression Testing, Node Mocking, Test Automation},
location = {Amsterdam, Netherlands},
series = {GPCE 2016}
}

@article{10.1145/3093335.2993257,
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
title = {Automated Regression Testing of BPMN 2.0 Processes: A Capture and Replay Framework for Continuous Delivery},
year = {2016},
issue_date = {March 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/3093335.2993257},
doi = {10.1145/3093335.2993257},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture &amp; replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {178–189},
numpages = {12},
keywords = {jBPM, Performance Overhead, BPMN 2.0, Business Process Execution, Test Automation, Node Mocking, Regression Testing}
}

@inproceedings{10.1145/2670979.2671004,
author = {Li, Kaituo and Joshi, Pallavi and Gupta, Aarti and Ganai, Malay K.},
title = {ReproLite: A Lightweight Tool to Quickly Reproduce Hard System Bugs},
year = {2014},
isbn = {9781450332521},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2670979.2671004},
doi = {10.1145/2670979.2671004},
abstract = {Cloud systems have become ubiquitous today -- they are used to store and process the tremendous amounts of data being generated by Internet users. These systems run on hundreds of commodity machines, and have a huge amount of non-determinism (thousands of threads and hundreds of processes) in their execution. Therefore, bugs that occur in cloud systems are hard to understand, reproduce, and fix. The state-of-the-art of debugging in the industry is to log messages during execution, and refer to those messages later in case of errors. In ReproLite, we augment the already widespread process of debugging using logs by enabling testers to quickly and easily specify the conjectures that they form regarding the cause of an error (or bug) from execution logs, and to also automatically validate those conjectures.ReproLite includes a Domain Specific Language (DSL) that allows testers to specify all aspects of a potential scenario (e.g., specific workloads, execution operations and their orders, environment non-determinism) that causes a given bug. Given such a scenario, ReproLite can enforce the conditions in the scenario during system execution. Potential buggy scenarios can also be automatically generated from a sequence of log messages that a tester believes indicates the cause of the bug. We have experimented ReproLite with 11 bugs from two popular cloud systems, Cassandra and HBase. We were able to reproduce all of the bugs using ReproLite. We report on our experience with using ReproLite on those bugs.},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {1–13},
numpages = {13},
keywords = {Lightweight, Hard System Bug, Debugging, Cloud Computing},
location = {Seattle, WA, USA},
series = {SOCC '14}
}

@inproceedings{10.1145/2884781.2884809,
author = {Menendez, David and Nagarakatte, Santosh},
title = {Termination-Checking for LLVM Peephole Optimizations},
year = {2016},
isbn = {9781450339001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2884781.2884809},
doi = {10.1145/2884781.2884809},
abstract = {Mainstream compilers contain a large number of peephole optimizations, which perform algebraic simplification of the input program with local rewriting of the code. These optimizations are a persistent source of bugs. Our recent research on Alive, a domain-specific language for expressing peephole optimizations in LLVM, addresses a part of the problem by automatically verifying the correctness of these optimizations and generating C++ code for use with LLVM.This paper identifies a class of non-termination bugs that arise when a suite of peephole optimizations is executed until a fixed point. An optimization can undo the effect of another optimization in the suite, which results in non-terminating compilation. This paper (1) proposes a methodology to detect non-termination bugs with a suite of peephole optimizations, (2) identifies the necessary condition to ensure termination while composing peephole optimizations, and (3) provides debugging support by generating concrete input programs that cause non-terminating compilation. We have discovered 184 optimization sequences, involving 38 optimizations, that cause non-terminating compilation in LLVM with Alive-generated C++ code.},
booktitle = {Proceedings of the 38th International Conference on Software Engineering},
pages = {191–202},
numpages = {12},
keywords = {compiler verification, alive, termination, peephole optimization},
location = {Austin, Texas},
series = {ICSE '16}
}

@article{10.1145/1416563.1416566,
author = {Huang, Shan Shan and Zook, David and Smaragdakis, Yannis},
title = {Domain-Specific Languages and Program Generation with Meta-AspectJ},
year = {2008},
issue_date = {November 2008},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/1416563.1416566},
doi = {10.1145/1416563.1416566},
abstract = {Meta-AspectJ (MAJ) is a language for generating AspectJ programs using code templates. MAJ itself is an extension of Java, so users can interleave arbitrary Java code with AspectJ code templates. MAJ is a structured metaprogramming tool: a well-typed generator implies a syntactically correct generated program. MAJ promotes a methodology that combines aspect-oriented and generative programming. A valuable application is in implementing small domain-specific language extensions as generators using unobtrusive annotations for syntax extension and AspectJ as a back-end. The advantages of this approach are twofold. First, the generator integrates into an existing software application much as a regular API or library, instead of as a language extension. Second, a mature language implementation is easy to achieve with little effort since AspectJ takes care of the low-level issues of interfacing with the base Java language.In addition to its practical value, MAJ offers valuable insights to metaprogramming tool designers. It is a mature metaprogramming tool for AspectJ (and, by extension, Java): a lot of emphasis has been placed on context-sensitive parsing and error reporting. As a result, MAJ minimizes the number of metaprogramming (quote/unquote) operators and uses type inference to reduce the need to remember type names for syntactic entities.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {nov},
articleno = {6},
numpages = {32},
keywords = {program transformation, Metaprogramming, program verification, language extensions, program synthesis, domain-specific languages}
}

@inproceedings{10.1145/3011141.3011158,
author = {Longo, Douglas Hiura and Vilain, Patricia and da Silva, Lucas Pereira and Mello, Ronaldo dos Santos},
title = {A Web Framework for Test Automation: User Scenarios through User Interaction Diagrams},
year = {2016},
isbn = {9781450348072},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3011141.3011158},
doi = {10.1145/3011141.3011158},
abstract = {This paper presents a web framework for test automation. This framework automates tests specified using the technique User Scenarios through User Interaction Diagrams (US-UID). US-UIDs represent customer requirements and are created a priori to the development of the application code. The goal of this proposal is the execution of US-UIDs as acceptance tests to check the application code in the context of Acceptance Test-Driven Development (ATDD). The implementation of the proposed framework uses FitNesse as its base and adds an editor for creating and executing US-UIDs. The proposal is exemplified by US-UIDs of the 8-puzzle game and evaluates the code of a Web-based application. The results show that US-UID has an executable format as automated tests. In addition, the proposed web framework has the capability of indicating the success, error or failure of interaction between a US-UID and the application code.},
booktitle = {Proceedings of the 18th International Conference on Information Integration and Web-Based Applications and Services},
pages = {458–467},
numpages = {10},
keywords = {acceptance test, automated test, ATDD, user interaction diagram, FitNesse, user scenario, UID, US-UID},
location = {Singapore, Singapore},
series = {iiWAS '16}
}

@inproceedings{10.1145/1866307.1866358,
author = {Henecka, Wilko and K \"{o}gl, Stefan and Sadeghi, Ahmad-Reza and Schneider, Thomas and Wehrenberg, Immo},
title = {TASTY: Tool for Automating Secure Two-Party Computations},
year = {2010},
isbn = {9781450302456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1866307.1866358},
doi = {10.1145/1866307.1866358},
abstract = {Secure two-party computation allows two untrusting parties to jointly compute an arbitrary function on their respective private inputs while revealing no information beyond the outcome. Existing cryptographic compilers can automatically generate secure computation protocols from high-level specifications, but are often limited in their use and efficiency of generated protocols as they are based on either garbled circuits or (additively) homomorphic encryption only.In this paper we present TASTY, a novel tool for automating, i.e., describing, generating, executing, benchmarking, and comparing, efficient secure two-party computation protocols. TASTY is a new compiler that can generate protocols based on homomorphic encryption and efficient garbled circuits as well as combinations of both, which often yields the most efficient protocols available today. The user provides a high-level description of the computations to be performed on encrypted data in a domain-specific language. This is automatically transformed into a protocol. TASTY provides most recent techniques and optimizations for practical secure two-party computation with low online latency. Moreover, it allows to efficiently evaluate circuits generated by the well-known Fairplay compiler.We use TASTY to compare protocols for secure multiplication based on homomorphic encryption with those based on garbled circuits and highly efficient Karatsuba multiplication. Further, we show how TASTY improves the online latency for securely evaluating the AES functionality by an order of magnitude compared to previous software implementations. TASTY allows to automatically generate efficient secure protocols for many privacy-preserving applications where we consider the use cases for private set intersection and face recognition protocols.},
booktitle = {Proceedings of the 17th ACM Conference on Computer and Communications Security},
pages = {451–462},
numpages = {12},
keywords = {secure function evaluation, compiler, garbled circuits, homomorphic encryption, cryptography},
location = {Chicago, Illinois, USA},
series = {CCS '10}
}

@inproceedings{10.1145/2038558.2038583,
author = {D\'{\i}az, Oscar and Puente, Gorka},
title = {Wiki Scaffolding: Helping Organizations to Set up Wikis},
year = {2011},
isbn = {9781450309097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2038558.2038583},
doi = {10.1145/2038558.2038583},
abstract = {Organizational wikis are framed by an existing organization. This makes these wikis be especially vigilant upon (1) facilitating the alignment of the wiki with organizational practices, (2) engaging management or (3), promoting employees' participation. To this end, we advocate for the use of "wiki scaffoldings". A wiki scaffolding is a wiki installation that is provided at the onset, before any contribution is made. It aims to frame wiki contribution along the concerns already known in the hosting organization in terms of glossaries, schedules, organigrams and the like. Thus, wiki contributions do not start from scratch but within a known setting. This paper introduces a language to capture wiki scaffolding in terms of FreeMind's mind maps. These maps can later be mapped into wiki installations in MediaWiki. The paper seeks to validate the approach in a twofold manner. Firstly, by providing literature quotes that suggest the need for scaffolding. Secondly, by providing scaffolding examples for wikis reported in the literature. The findings suggest that wiki scaffolding can be useful to smoothly align wiki activity along the practices of the hosting organization from the onset.},
booktitle = {Proceedings of the 7th International Symposium on Wikis and Open Collaboration},
pages = {154–162},
numpages = {9},
keywords = {DSL, collaboration, wiki scaffolding, wikis},
location = {Mountain View, California},
series = {WikiSym '11}
}

@inproceedings{10.1145/3550355.3552451,
author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Suny\'{e}, Gerson and G\'{o}mez-Abajo, Pablo and Ca\~{n}izares, Pablo C. and Guerra, Esther and de Lara, Juan},
title = {Automatic Test Amplification for Executable Models},
year = {2022},
isbn = {9781450394666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550355.3552451},
doi = {10.1145/3550355.3552451},
abstract = {Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test cases of behavioral models.In this paper, we fill this gap with an automated and generic approach. Given an executable DSL, a conforming behavioral model, and an existing test suite, our approach generates new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the mutation score. We provide tool support for the approach atop the Eclipse GEMOC Studio1 and show its applicability in an empirical study. In the experiment, we applied the approach to 71 test suites written for models conforming to two different DSLs, and for 67 of the 71 cases, it successfully improved the mutation score between 3.17% and 54.11% depending on the initial setup.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
pages = {109–120},
numpages = {12},
keywords = {regression testing, test amplification, executable DSL, executable model},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/2555523.2555535,
author = {da Silva, Elias Adriano Nogueira and Fortes, Renata P. M. and Lucr\'{e}dio, Daniel},
title = {A Model-Driven Approach for Promoting Cloud PaaS Portability},
year = {2013},
publisher = {IBM Corp.},
address = {USA},
abstract = {Cloud computing has become an important research subject in software engineering. Among the many research gaps related to this new computing model is the lack of portability between cloud platforms, which generates the Lock-In problem. The Lock-In is the difficulty in migrating data and applications from a cloud platform to another. Current attempts to address this problem revolve around standardization of APIs and frameworks. We propose a different path, using model-driven engineering (MDE). We selected two cloud platforms and built a DSL and a set of automated transformations that generate code for each platform, based on a single portable model. We present the results of two studies. In a first study, subjects were asked to use the two versions of the same application, each one generated for a different platform from a single model. The subjects did not notice any difference between the two versions in terms of functionality. In a second study, we observed that besides facilitating cloud portability, MDE can increase productivity and reusability. These results indicate that MDE may be an alternative to standardization, not only helping to solve portability problems but also leading to additional benefits.},
booktitle = {Proceedings of the 2013 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {92–105},
numpages = {14},
location = {Ontario, Canada},
series = {CASCON '13}
}

@inproceedings{10.1145/3152688.3152692,
author = {Gabrielova, Eugenia},
title = {End-to-End Regression Testing for Distributed Systems},
year = {2017},
isbn = {9781450351997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3152688.3152692},
doi = {10.1145/3152688.3152692},
abstract = {Even with substantial advances in tools and research techniques, distributed systems remain challenging to test. One frustrating aspect of distributed systems development is the resurfacing of old problems due to code changes. Regression test suites replicate previously known bugs and ensure they do not resurface as the code evolves. Conventional unit regression tests miss a substantial amount of distributed system problems; end-to-end testing is almost always required in order to reproduce complex bugs. We describe a framework for regression testing that bridges a gap between local ad-hoc experiments and end-to-end stress testing, potentially lowering the recurrence of critical bugs.},
booktitle = {Proceedings of the 18th Doctoral Symposium of the 18th International Middleware Conference},
pages = {9–12},
numpages = {4},
location = {Las Vegas, Nevada},
series = {Middleware '17}
}

@inproceedings{10.1145/3393527.3393531,
author = {Zhang, Yuxiang and Chen, Kang and Liu, Weidong},
title = {Online Judge for FPGA-Based Lab Projects in Computer Organization Course},
year = {2020},
isbn = {9781450375344},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3393527.3393531},
doi = {10.1145/3393527.3393531},
abstract = {While online judge systems are widely used in programming related courses, they are rarely used in hardware-related courses such as the computer organization course requiring the digital circuit design. With the widely available FPGA hardware, students now have fewer difficulties in building hardware by only writing hardware description language (HDL) code. We have built a cloud-based lab environment that students can build CPUs online by submitting their Verilog HDL code. Our HDL online judge system is applied to test the submitted code. It greatly reduces the efforts of checking the code manually.},
booktitle = {Proceedings of the ACM Turing Celebration Conference - China},
pages = {15–20},
numpages = {6},
keywords = {Computer Organization, FPGA, Digital Circuit, Online Judge},
location = {Hefei, China},
series = {ACM TURC'20}
}

@inproceedings{10.1145/3293882.3330561,
author = {Golagha, Mojdeh and Lehnhoff, Constantin and Pretschner, Alexander and Ilmberger, Hermann},
title = {Failure Clustering without Coverage},
year = {2019},
isbn = {9781450362245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3293882.3330561},
doi = {10.1145/3293882.3330561},
abstract = {Developing and integrating software in the automotive industry is a complex task and requires extensive testing. An important cost factor in testing and debugging is the time required to analyze failing tests. In the context of regression testing, usually, large numbers of tests fail due to a few underlying faults. Clustering failing tests with respect to their underlying faults can, therefore, help in reducing the required analysis time. In this paper, we propose a clustering technique to group failing hardware-in-the-loop tests based on non-code-based features, retrieved from three different sources. To effectively reduce the analysis effort, the clustering tool selects a representative test for each cluster. Instead of analyzing all failing tests, testers only inspect the representative tests to find the underlying faults. We evaluated the effectiveness and efficiency of our solution in a major automotive company using 86 regression test runs, 8743 failing tests, and 1531 faults. The results show that utilizing our clustering tool, testers can reduce the analysis time more than 60% and find more than 80% of the faults only by inspecting the representative tests.},
booktitle = {Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {134–145},
numpages = {12},
keywords = {Failure Clustering, Debugging},
location = {Beijing, China},
series = {ISSTA 2019}
}

@inproceedings{10.1145/3183440.3195036,
author = {Santos, Ernani C\'{e}sar Dos and Vilain, Patr\'{\i}cia and Longo, Douglas Hiura},
title = {A Systematic Literature Review to Support the Selection of User Acceptance Testing Techniques},
year = {2018},
isbn = {9781450356633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183440.3195036},
doi = {10.1145/3183440.3195036},
abstract = {User Acceptance Testing (UAT) aims to determine whether or not a software satisfies users acceptance criteria. Although some studies have used acceptance tests as software requirements, no previous study has collected information about available UAT techniques and established a comparison of them, to support an organization in the selection of one over another. This work presents a Systematic Literature Review on UAT to find out available techniques and compare their main features. We selected 80 studies and found out 21 UAT techniques. As result, we created a comparative table summarizing these techniques and their features.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings},
pages = {418–419},
numpages = {2},
keywords = {classification, features, techniques, user acceptance testing},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@inproceedings{10.1145/3425174.3425213,
author = {Toennemann, Jan and Anicul\u{a}esei, Adina and Rausch, Andreas},
title = {Asserting Functional Equivalence between C Code and SCADE Models in Code-to-Model Transformations},
year = {2020},
isbn = {9781450387552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3425174.3425213},
doi = {10.1145/3425174.3425213},
abstract = {Model-based development is on the rise and tool chains employing automated code generation from models using certified code generators are getting increasingly common. We present an approach which enables the reverse operation and creates an ANSYS SCADE model that is functionally equivalent to the C code. The main motivation behind this development is to enable original equipment manufacturers (OEMs) to further use and maintain legacy code in new development environments, rather than having to re-develop the respective functionality from scratch.While the model transformation itself is performed manually, the testing process is fully automated and enabled the transfer of existing test cases for the C function to the SCADE Test Environment. The presented approach enables white-box testing of the model, requiring the original C implementation and its original test cases as well as a bi-directional mapping of variable names between C code and SCADE model. This is done by extending the original code in a way that generates SCADE test scenarios during runtime, allowing to use these white-box test scenarios to assert functional equivalence of code and model using empirical validation.},
booktitle = {Proceedings of the 5th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {60–68},
numpages = {9},
keywords = {test case generation, equivalence testing, embedded software, ANSYS SCADE model, C code, test automation, model-driven engineering, code-to-model transformation, white-box testing},
location = {Natal, Brazil},
series = {SAST 20}
}

@inproceedings{10.1145/3375959.3375967,
author = {Wolde, Behailu Getachew and Boltana, Abiot Sinamo},
title = {Combinatorial Testing Approach for Cloud Mobility Service},
year = {2020},
isbn = {9781450372633},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3375959.3375967},
doi = {10.1145/3375959.3375967},
abstract = {Currently, software product becomes an essential component in running many stakeholders' activities. For instance, the industries mostly use cloud services to execute their important business functionality. However, by a few input's parameter interacting, this functionality can be pended. Such constraint poses challenging to cover various features of failure especially in ensuring cloud application. One way is to devise a strategy to cover input parameters' characteristics based on Combinatorial testing approach. This technique includes all possible combinations of test inputs for detecting bugs on the System Under Test (SUT). The paper explains the Combinatorial covering arrays to generate relatively exhaustive testing by modeling features of sample services using Feature IDE plugin in Eclipse IDE. This way, we build the input domain model to represent coverage of the existing mobility service running on NEMo Mobility cloud platform. Using this model, covering arrays is applied to generate t-way test cases by leveraging IPOg algorithm, which is implemented in a CiTLab. As a test case management, the JUnit testing framework uses test stubs to validate the test methods of generated test cases on the specified service (SUT).},
booktitle = {Proceedings of the 2019 2nd Artificial Intelligence and Cloud Computing Conference},
pages = {6–13},
numpages = {8},
keywords = {CiTLAB, Software Testing, Feature Model, Cloud Mobility Service, Combinatorial Testing},
location = {Kobe, Japan},
series = {AICCC 2019}
}

@inproceedings{10.1145/2997364.2997367,
author = {Meyers, Bart and Denil, Joachim and D\'{a}vid, Istv\'{a}n and Vangheluwe, Hans},
title = {Automated Testing Support for Reactive Domain-Specific Modelling Languages},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2997364.2997367},
doi = {10.1145/2997364.2997367},
abstract = {Domain-specific modelling languages (DSML) enable domain users to model systems in their problem domain, using concepts and notations they are familiar with. The process of domain-specific modelling (DSM) consists of two stages: a language engineering stage where a DSML is created, and a system modelling stage where the DSML is used. Because techniques such as metamodelling and model transformation allow for a efficient creation of DSMLs, and using DSMLs significantly increases productivity, DSM is very suitable for early prototyping. Many systems that are modelled using DSMLs are reactive, meaning that during their execution, they respond to external input. Because of the complexity of input and response behaviour of reactive systems, it is desirable to test models as early as possible. However, while dedicated testing support for specific DSMLs has been provided, no systematic support exists for testing DSML models according to DSM principles. In this paper, we introduce a technique to automatically generate a domain-specific testing framework from an annotated DSML definition. In our approach, the DSML definition consists of a metamodel, a concrete syntax definition and operational semantics described as a schedule of graph rewrite rules, thus covering a large class of DSMLs. Currently, DSMLs with deterministic behaviour are supported, but we provide an outlook to other (nondeterministic, real-time or continuous-time) DSMLs. We illustrate the approach with a DSML for describing an elevator controller. We evaluate the approach and conclude that compared to the state-of-the-art, our testing support is significantly less costly, and similar or better (according to DSM principles) testing support is achieved. Additionally, the generative nature of the approach makes testing support for DSMLs less error-prone while catering the need for early testing.},
booktitle = {Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
pages = {181–194},
numpages = {14},
keywords = {Language Engineering, Domain-Specific Modelling, Verification},
location = {Amsterdam, Netherlands},
series = {SLE 2016}
}

@inproceedings{10.1145/3184558.3191656,
author = {Vu, Henry and Fertig, Tobias and Braun, Peter},
title = {Verification of Hypermedia Characteristic of RESTful Finite-State Machines},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191656},
doi = {10.1145/3184558.3191656},
abstract = {Being an architectural style rather than a specification or a standard, the proper design of REpresentational State Transfer (REST) APIs is not trivial, since developers have to deal with a flood of recommendations and best practices, especially the proper application of the hypermedia constraint requires some decent experience. Furthermore, testing RESTful APIs is a missing topic within literature and especially, hypermedia testing is not mentioned at all. To deal with this state of affairs, we have elaborated a Model-Driven Software Development (MDSD) approach for creating RESTful APIs. As this project matured, we also explored the possibility of Model-Driven Testing (MDT). This work addresses the challenges of hypermedia testing and proposes approaches to overcome them with MDT techniques. We present the results of hypermedia testing for RESTful APIs using a model verification approach that were discovered within our research. MDT enables the verification of the underlying model of a RESTful API and ensuring its correctness before initiating any code generation. Therefore, we can prevent a poorly designed model from being transformed into a poorly designed RESTful API.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1881–1886},
numpages = {6},
keywords = {MDT, hypermedia testing, RESTful systems, MDSD, hypermedia, RESTful applications, REST},
location = {Lyon, France},
series = {WWW '18}
}

@proceedings{10.1145/2997364,
title = {SLE 2016: Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering},
year = {2016},
isbn = {9781450344470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Amsterdam, Netherlands}
}

@article{10.1145/3210256,
author = {Florence, Spencer P. and Fetscher, Burke and Flatt, Matthew and Temps, William H. and St-Amour, Vincent and Kiguradze, Tina and West, Dennis P. and Niznik, Charlotte and Yarnold, Paul R. and Findler, Robert Bruce and Belknap, Steven M.},
title = {POP-PL: A Patient-Oriented Prescription Programming Language},
year = {2018},
issue_date = {September 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {40},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/3210256},
doi = {10.1145/3210256},
abstract = {A medical prescription is a set of health care instructions that govern the plan of care for an individual patient, which may include orders for drug therapy, diet, clinical assessment, and laboratory testing. Clinicians have long used algorithmic thinking to describe and implement prescriptions but without the benefit of a formal programming language. Instead, medical algorithms are expressed using a natural language patois, flowcharts, or as structured data in an electronic medical record system. The lack of a prescription programming language inhibits expressiveness; results in prescriptions that are difficult to understand, hard to debug, and awkward to reuse; and increases the risk of fatal medical error.This article reports on the design and evaluation of Patient-Oriented Prescription Programming Language (POP-PL), a domain-specific programming language designed for expressing prescriptions. The language is based around the idea that programs and humans have complementary strengths that, when combined properly, can make for safer, more accurate performance of prescriptions. Use of POP-PL facilitates automation of certain low-level vigilance tasks, freeing up human cognition for abstract thinking, compassion, and human communication.We implemented this language and evaluated its design attempting to write prescriptions in the new language and evaluated its usability by assessing whether clinicians can understand and modify prescriptions written in the language. We found that some medical prescriptions can be expressed in a formal domain-specific programming language, and we determined that medical professionals can understand and correctly modify programs written in POP-PL. We also discuss opportunities for refining and further developing POP-PL.},
journal = {ACM Trans. Program. Lang. Syst.},
month = {jul},
articleno = {10},
numpages = {37},
keywords = {medical prescriptions, DSL design, medical programming languages, empirical evaluation}
}

@inproceedings{10.1109/ICSE-SEIP.2019.00035,
author = {Giorgi, Fabio and Paulisch, Frances},
title = {Transition towards Continuous Delivery in the Healthcare Domain},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP.2019.00035},
doi = {10.1109/ICSE-SEIP.2019.00035},
abstract = {Continuous Delivery is meanwhile well-established in many parts of the software industry. In a transition towards continuous delivery in the healthcare domain, there are a number of additional challenges that should be addressed. We present how we have addressed some of these challenges and highlight some potential research topics that could be addressed in this space to make further progress in this important area. Although our focus is on the healthcare domain, the approach and the research topics are applicable also to a broad range of other application domains.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice},
pages = {253–254},
numpages = {2},
keywords = {domain-driven design, deployment pipeline, test-driven development, test automation, agile, continuous delivery, behavior-driven development, pair-programming},
location = {Montreal, Quebec, Canada},
series = {ICSE-SEIP '19}
}

@inproceedings{10.1145/3524481.3527239,
author = {Eisner, Daniel and Wuersching, Roland and Schnappinger, Markus and Pretschner, Alexander},
title = {Probe-Based Syscall Tracing for Efficient and Practical File-Level Test Traces},
year = {2022},
isbn = {9781450392860},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524481.3527239},
doi = {10.1145/3524481.3527239},
abstract = {Efficiently collecting per-test execution traces is a common prerequisite of dynamic regression test optimization techniques. However, as these test traces are typically recorded through language-specific code instrumentation, non-code artifacts and multi-language source code are usually not included. In contrast, more complete test traces can be obtained by instrumenting operating system calls and thereby tracing all accessed files during a test's execution. Yet, existing test optimization techniques that use syscall tracing are impractical as they either modify the Linux kernel or operate in user space, thus raising transferability, performance, and security concerns. Recent advances in operating system development provide versatile, lightweight, and safe kernel instrumentation frameworks: They allow to trace syscalls by instrumenting probes in the operating system kernel. Probe-based Syscall Tracing (ProST), our novel technique, harnesses this potential to collect file-level test traces that go beyond language boundaries and consider non-code artifacts. To evaluate ProST's efficiency and the completeness of obtained test traces, we perform an empirical study on 25 multi-language open-source software projects and compare our approach to existing language-specific instrumentation techniques. Our results show that most studied projects use source files from multiple languages (22/25) or non-code artifacts during testing (22/25) that are missed by language-specific techniques. With the low execution time overhead of 4.6% compared to non-instrumented test execution, ProST is more efficient than language-specific instrumentation. Furthermore, it collects on average 89% more files on top of those collected by language-specific techniques. Consequently, ProST paves the way for efficiently extracting valuable information through dynamic analysis to better understand and optimize testing in multi-language software systems.},
booktitle = {Proceedings of the 3rd ACM/IEEE International Conference on Automation of Software Test},
pages = {126–137},
numpages = {12},
keywords = {multi-language software, non-code artifacts, dynamic program analysis, software testing},
location = {Pittsburgh, Pennsylvania},
series = {AST '22}
}

@inproceedings{10.5555/2337223.2337371,
author = {Devos, Nicolas and Ponsard, Christophe and Deprez, Jean-Christophe and Bauvin, Renaud and Moriau, Benedicte and Anckaerts, Guy},
title = {Efficient Reuse of Domain-Specific Test Knowledge: An Industrial Case in the Smart Card Domain},
year = {2012},
isbn = {9781467310673},
publisher = {IEEE Press},
abstract = {While testing is heavily used and largely automated in software development projects, the reuse of test practices across similar projects in a given domain is seldom systematized and supported by adequate methods and tools. This paper presents a practical approach that emerged from a concrete industrial case in the smart card domain at STMicroelectronics Belgium in order to better address this kind of challenge. The central concept is a test knowledge repository organized as a collection of specific patterns named QPatterns. A systematic process was followed, first to gather, structure and abstract the test practices, then to produce and validate an initial repository, and finally to make it evolve later on Testers can then rely on this repository to produce high quality test plans identifying all the functional and non-functional aspects that have to be addressed, as well as the concrete tests that have to be developed within the context of a new project. A tool support was also developed and integrated in a traceable way into the existing industrial test environment. The approach was validated and is currently under deployment at STMicroelectronics Belgium.},
booktitle = {Proceedings of the 34th International Conference on Software Engineering},
pages = {1123–1132},
numpages = {10},
location = {Zurich, Switzerland},
series = {ICSE '12}
}

@inproceedings{10.1145/2607023.2610278,
author = {Hesenius, Marc and Griebe, Tobias and Gruhn, Volker},
title = {Towards a Behavior-Oriented Specification and Testing Language for Multimodal Applications},
year = {2014},
isbn = {9781450327251},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2607023.2610278},
doi = {10.1145/2607023.2610278},
abstract = {Initiated by the ubiquity of mobile devices, human computer interaction has evolved beyond the classic PCs' mouse and keyboard setup. Smartphones and tablets introduced new interaction modalities to the mass market and created the need for specialized software engineering methods. While more and more powerful SDKs are released to develop interactive applications, specifying user interaction is still ambiguous and error-prone, causing software defects as well as misunderstandings and frustration among project team members and stakeholders. We present an approach addressing this problems by demonstrating how to incorporate multimodal interaction into user acceptance tests written in near-natural language using Gherkin and formal gesture descriptions.},
booktitle = {Proceedings of the 2014 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {117–122},
numpages = {6},
keywords = {multimodal user interfaces, specification, software engineering},
location = {Rome, Italy},
series = {EICS '14}
}

@inproceedings{10.1145/2134243.2134248,
author = {Sadowski, Caitlin and Yi, Jaeheon},
title = {<u>T</u>i<u>d</u>d<u>l</u>e: A <u>t</u>race <u>d</u>escription <u>l</u>anguage for Generating Concurrent Benchmarks to Test Dynamic Analyses},
year = {2009},
isbn = {9781605586564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2134243.2134248},
doi = {10.1145/2134243.2134248},
abstract = {Dynamic analysis is a promising technique for finding concurrency bugs in multithreaded programs. However, testing a dynamic analysis tool can be difficult. Researchers end up writing large amounts of small benchmark programs. Since the benchmarks themselves are concurrent programs, they may execute nondeterministically, complicating testing of the analysis tool.We propose testing dynamic analyses by writing traces in a simple trace description language, Tiddle. Our implementation, written in Haskell, generates deterministic multithreaded Java programs for testing dynamic analyses. We report that it is substantially easier to write programs with incriminating bugs such as race conditions in Tiddle than the corresponding Java source code version, reducing the amount of source code to maintain and understand. Although our implementation is targeted towards Java, the ideas extend to any other languages which support mutable fields and multiple threads.},
booktitle = {Proceedings of the Seventh International Workshop on Dynamic Analysis},
pages = {15–21},
numpages = {7},
keywords = {race conditions, atomicity violations, dynamic analysis, concurrency, traces},
location = {Chicago, Illinois},
series = {WODA '09}
}

@inproceedings{10.5555/2663575.2663588,
author = {Morrison, Patrick and Holmgreen, Casper and Massey, Aaron and Williams, Laurie},
title = {Proposing Regulatory-Driven Automated Test Suites for Electronic Health Record Systems},
year = {2013},
isbn = {9781467362825},
publisher = {IEEE Press},
abstract = {In regulated domains such as finance and health care, failure to comply with regulation can lead to financial, civil and criminal penalties. While systems vary from organization to organization, regulations apply across organizations. We propose the use of Behavior-Driven-Development (BDD) scenarios as the basis of an automated compliance test suite for standards such as regulation and interoperability. Such test suites could become a shared asset for use by all systems subject to these regulations and standards. Each system, then, need only create their own system-specific test driver code to automate their compliance checks. The goal of this research is to enable organizations to compare their systems to regulation in a repeatable and traceable way through the use of BDD. To evaluate our proposal, we developed an abbreviated HIPAA test suite and applied it to three open-source electronic health record systems. The scenarios covered all security behavior defined by the selected regulation. The system-specific test driver code covered all security behavior defined in the scenarios, and identified where the tested system lacked such behavior.},
booktitle = {Proceedings of the 5th International Workshop on Software Engineering in Health Care},
pages = {46–49},
numpages = {4},
keywords = {software engineering, healthcare it, behavior-driven-development, security, regulatory compliance, software testing},
location = {San Francisco, California},
series = {SEHC '13}
}

@inproceedings{10.1145/3379597.3387482,
author = {Pinto, Gustavo and Miranda, Breno and Dissanayake, Supun and d'Amorim, Marcelo and Treude, Christoph and Bertolino, Antonia},
title = {What is the Vocabulary of Flaky Tests?},
year = {2020},
isbn = {9781450375177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3379597.3387482},
doi = {10.1145/3379597.3387482},
abstract = {Flaky tests are tests whose outcomes are non-deterministic. Despite the recent research activity on this topic, no effort has been made on understanding the vocabulary of flaky tests. This work proposes to automatically classify tests as flaky or not based on their vocabulary. Static classification of flaky tests is important, for example, to detect the introduction of flaky tests and to search for flaky tests after they are introduced in regression test suites.We evaluated performance of various machine learning algorithms to solve this problem. We constructed a data set of flaky and non-flaky tests by running every test case, in a set of 64k tests, 100 times (6.4 million test executions). We then used machine learning techniques on the resulting data set to predict which tests are flaky from their source code. Based on features, such as counting stemmed tokens extracted from source code identifiers, we achieved an F-measure of 0.95 for the identification of flaky tests. The best prediction performance was obtained when using Random Forest and Support Vector Machines. In terms of the code identifiers that are most strongly associated with test flakiness, we noted that job, action, and services are commonly associated with flaky tests. Overall, our results provides initial yet strong evidence that static detection of flaky tests is effective.},
booktitle = {Proceedings of the 17th International Conference on Mining Software Repositories},
pages = {492–502},
numpages = {11},
keywords = {Text classification, Regression testing, Test flakiness},
location = {Seoul, Republic of Korea},
series = {MSR '20}
}

@inproceedings{10.1145/331960.331968,
author = {Reichwein, James and Rothermel, Gregg and Burnett, Margaret},
title = {Slicing Spreadsheets: An Integrated Methodology for Spreadsheet Testing and Debugging},
year = {2000},
isbn = {1581132557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/331960.331968},
doi = {10.1145/331960.331968},
abstract = {Spreadsheet languages, which include commercial spreadsheets and various research systems, have proven to be flexible tools in many domain specific settings. Research shows, however, that spreadsheets often contain faults. We would like to provide at least some of the benefits of formal testing and debugging methodologies to spreadsheet developers. This paper presents an integrated testing and debugging methodology for spreadsheets. To accommodate the modeless and incremental development, testing and debugging activities that occur during spreadsheet creation, our methodology is tightly integrated into the spreadsheet environment. To accommodate the users of spreadsheet languages, we provide an interface to our methodology that does not require an understanding of testing and debugging theory, and that takes advantage of the immediate visual feedback that is characteristic of the spreadsheet paradigm.},
booktitle = {Proceedings of the 2nd Conference on Domain-Specific Languages},
pages = {25–38},
numpages = {14},
location = {Austin, Texas, USA},
series = {DSL '99}
}

@article{10.1145/331963.331968,
author = {Reichwein, James and Rothermel, Gregg and Burnett, Margaret},
title = {Slicing Spreadsheets: An Integrated Methodology for Spreadsheet Testing and Debugging},
year = {2000},
issue_date = {Jan. 2000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {35},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/331963.331968},
doi = {10.1145/331963.331968},
abstract = {Spreadsheet languages, which include commercial spreadsheets and various research systems, have proven to be flexible tools in many domain specific settings. Research shows, however, that spreadsheets often contain faults. We would like to provide at least some of the benefits of formal testing and debugging methodologies to spreadsheet developers. This paper presents an integrated testing and debugging methodology for spreadsheets. To accommodate the modeless and incremental development, testing and debugging activities that occur during spreadsheet creation, our methodology is tightly integrated into the spreadsheet environment. To accommodate the users of spreadsheet languages, we provide an interface to our methodology that does not require an understanding of testing and debugging theory, and that takes advantage of the immediate visual feedback that is characteristic of the spreadsheet paradigm.},
journal = {SIGPLAN Not.},
month = {dec},
pages = {25–38},
numpages = {14}
}

@article{10.1145/1507195.1517461,
author = {Torkar, Richard and Gorschek, Tony and Feldt, Robert},
title = {Eight Conference on Software Engineering Research and Practice in Sweden (SERPS'08)},
year = {2009},
issue_date = {March 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {0163-5948},
url = {https://doi.org/10.1145/1507195.1517461},
doi = {10.1145/1507195.1517461},
abstract = {The eight conference on software engineering research and practice in Sweden (SERPS'08) was held in Karlskrona, Sweden, on the 4th-5th of Nov. 2008. The aim with SERPS'08 is to bring researchers and industry practitioners together to discuss software engineering issues, problems, solutions and experiences, not necessarily from a Swedish perspective. During the conference a number of research and industry papers were presented and questions in connection to the presentations were discussed. This paper is a report on the discussions that took place, pointing towards needs and challenges as well as areas of interest in both academia and industry.},
journal = {SIGSOFT Softw. Eng. Notes},
month = {feb},
pages = {31–33},
numpages = {3}
}

@inproceedings{10.1145/3350768.3351300,
author = {Kudo, Taciana Novo and Bulc\~{a}o-Neto, Renato F. and Vincenzi, Auri M. R.},
title = {A Conceptual Metamodel to Bridging Requirement Patterns to Test Patterns},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3351300},
doi = {10.1145/3350768.3351300},
abstract = {Requirement patterns represent an abstraction of an application's behaviors and services that, in turn, may be replicated in similar applications. However, there has been a lack of efforts exploiting the benefits of requirement patterns in other phases of the software development life cycle, besides the requirements engineering itself. To address this gap, we propose the Software Pattern MetaModel (SoPaMM) that bridges requirement patterns to groups of scenarios with similar behaviors in the form of test patterns. SoPaMM allows the description of the behavior of a requirement pattern through a time executable and easy-to-use language aiming at the automatic generation of test patterns. Using SoPaMM, we model and implement a behavior-driven functional requirement pattern for a web-based user authentication application. Our preliminary results point out that a requirement pattern can be an executable specification capable of generating automated tests.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {155–160},
numpages = {6},
keywords = {requirement pattern, test pattern, reuse, behavior, metamodeling},
location = {Salvador, Brazil},
series = {SBES '19}
}

@article{10.1145/3468504,
author = {Sundelin, Anders and Gonzalez-huerta, Javier and Wnuk, Krzysztof and Gorschek, Tony},
title = {Towards an Anatomy of Software Craftsmanship},
year = {2021},
issue_date = {January 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3468504},
doi = {10.1145/3468504},
abstract = {Context: The concept of software craftsmanship has early roots in computing, and in 2009, the Manifesto for Software Craftsmanship was formulated as a reaction to how the Agile methods were practiced and taught. But software craftsmanship has seldom been studied from a software engineering perspective.Objective: The objective of this article is to systematize an anatomy of software craftsmanship through literature studies and a longitudinal case study.Method: We performed a snowballing literature review based on an initial set of nine papers, resulting in&nbsp;18 papers and 11 books. We also performed a case study following seven years of software development of a product for the financial market, eliciting qualitative, and quantitative results. We used thematic coding to synthesize the results into categories.Results: The resulting anatomy is centered around four themes, containing 17 principles and 47 hierarchical practices connected to the principles. We present the identified practices based on the experiences gathered from the case study, triangulating with the literature results.Conclusion: We provide our systematically derived anatomy of software craftsmanship with the goal of inspiring more research into the principles and practices of software craftsmanship and how these relate to other principles within software engineering in general.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = {sep},
articleno = {6},
numpages = {49},
keywords = {principles of software development, deliberate practice, Software craftsmanship}
}

@inproceedings{10.1145/2628363.2628391,
author = {Hesenius, Marc and Griebe, Tobias and Gries, Stefan and Gruhn, Volker},
title = {Automating UI Tests for Mobile Applications with Formal Gesture Descriptions},
year = {2014},
isbn = {9781450330046},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2628363.2628391},
doi = {10.1145/2628363.2628391},
abstract = {Touch- and gesture-based interfaces are common in applications for mobile devices. By evolving into mass market products, smartphones and tablets created an increased need for specialized software engineering methods. To ensure high quality applications, constant and efficient testing is crucial in software development. However, testing mobile applications is still cumbersome, time-consuming and error-prone. One reason is the devices' focus on touch-based interaction - gestures cannot be easily incorporated into automated application tests. We present an extension to the popular Calabash testing framework solving this problem by allowing to describe gestures with a formal language in tests scripts.},
booktitle = {Proceedings of the 16th International Conference on Human-Computer Interaction with Mobile Devices &amp; Services},
pages = {213–222},
numpages = {10},
keywords = {gestures, software engineering, test automation, mobile applications, gesture formalization, testing},
location = {Toronto, ON, Canada},
series = {MobileHCI '14}
}

@inproceedings{10.1145/3350768.3350790,
author = {Diniz, Thomaz and Alves, Everton L.G. and Silva, Anderson G.F. and Andrade, Wilkerson L.},
title = {Reducing the Discard of MBT Test Cases Using Distance Functions},
year = {2019},
isbn = {9781450376518},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3350768.3350790},
doi = {10.1145/3350768.3350790},
abstract = {Model-Based Testing (MBT) is used for generating test suites from system models. However, as software evolves, its models tend to be updated, which often leads to obsolete test cases that are discarded. Test case discard can be very costly since essential data, such as execution history, are lost. In this paper, we investigate the use of distance functions to help to reduce the discard of MBT tests. For that, we ran a series of empirical studies using artifacts from industrial systems, and we analyzed how ten distance functions can classify the impact of MBT-centred use case edits. Our results showed that distance functions are effective for identifying low impact edits that lead to test cases that can be updated with little effort. Moreover, we found the optimal configuration for each distance function. Finally, we ran a case study that showed that, by using distance functions, we could reduce the discard of test cases by 15%.},
booktitle = {Proceedings of the XXXIII Brazilian Symposium on Software Engineering},
pages = {337–346},
numpages = {10},
keywords = {agile development, MBT, test suite evolution, distance functions},
location = {Salvador, Brazil},
series = {SBES '19}
}

@inproceedings{10.1145/2554850.2554942,
author = {Griebe, Tobias and Gruhn, Volker},
title = {A Model-Based Approach to Test Automation for Context-Aware Mobile Applications},
year = {2014},
isbn = {9781450324694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2554850.2554942},
doi = {10.1145/2554850.2554942},
abstract = {Current testing tools for mobile applications do not provide sufficient support for context-aware application testing. In addition to regular input vectors (e.g. touch events, text entry) context parameters must be considered (e.g. accelerometer data interpreted as shake gestures, GPS location data, etc.). A multitude of possible application faults resulting from these additional context parameters requires an appropriately selected set of test cases. In this paper, we propose a model-based approach to improve the testing of context-aware mobile applications by deducing test cases from design-time system models. Using a custom-built version of the calabash-android testing framework enhanced by an arbitrary context parameter facility, our approach to test case generation and automated execution is validated on a context-aware mobile application.},
booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
pages = {420–427},
numpages = {8},
keywords = {model-based, testing, context-awareness, mobile},
location = {Gyeongju, Republic of Korea},
series = {SAC '14}
}

@inproceedings{10.1145/3213846.3213852,
author = {Shin, Seung Yeob and Nejati, Shiva and Sabetzadeh, Mehrdad and Briand, Lionel C. and Zimmer, Frank},
title = {Test Case Prioritization for Acceptance Testing of Cyber Physical Systems: A Multi-Objective Search-Based Approach},
year = {2018},
isbn = {9781450356992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3213846.3213852},
doi = {10.1145/3213846.3213852},
abstract = {Acceptance testing validates that a system meets its requirements and determines whether it can be sufficiently trusted and put into operation. For cyber physical systems (CPS), acceptance testing is a hardware-in-the-loop process conducted in a (near-)operational environment. Acceptance testing of a CPS often necessitates that the test cases be prioritized, as there are usually too many scenarios to consider given time constraints. CPS acceptance testing is further complicated by the uncertainty in the environment and the impact of testing on hardware. We propose an automated test case prioritization approach for CPS acceptance testing, accounting for time budget constraints, uncertainty, and hardware damage risks. Our approach is based on multi-objective search, combined with a test case minimization algorithm that eliminates redundant operations from an ordered sequence of test cases. We evaluate our approach on a representative case study from the satellite domain. The results indicate that, compared to test cases that are prioritized manually by satellite engineers, our automated approach more than doubles the number of test cases that fit into a given time frame, while reducing to less than one third the number of operations that entail the risk of damage to key hardware components.},
booktitle = {Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {49–60},
numpages = {12},
keywords = {Multi-objective Optimization, Search-based Software Engineering, Acceptance Testing, Test Case Prioritization, Cyber Physical Systems},
location = {Amsterdam, Netherlands},
series = {ISSTA 2018}
}

@inproceedings{10.1145/3238147.3240463,
author = {Gafurov, Davrondzhon and Hurum, Arne Erik and Markman, Martin},
title = {Achieving Test Automation with Testers without Coding Skills: An Industrial Report},
year = {2018},
isbn = {9781450359375},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3238147.3240463},
doi = {10.1145/3238147.3240463},
abstract = {We present a process driven test automation solution which enables delegating (part of) automation tasks from test automation engineer (expensive resource) to test analyst (non-developer, less expensive). In our approach, a test automation engineer implements test steps (or actions) which are executed automatically. Such automated test steps represent user actions in the system under test and specified by a natural language which is understandable by a non-technical person. Then, a test analyst with a domain knowledge organizes automated steps combined with test input to create an automated test case. It should be emphasized that the test analyst does not need to possess programming skills to create, modify or execute automated test cases. We refine benchmark test automation architecture to be better suitable for an effective separation and sharing of responsibilities between the test automation engineer (with coding skills) and test analyst (with a domain knowledge). In addition, we propose a metric to empirically estimate cooperation between test automation engineer and test analyst's works. The proposed automation solution has been defined based on our experience in the development and maintenance of Helsenorg, the national electronic health services in Norway which has had over one million of visits per month past year, and we still use it to automate the execution of regression tests.},
booktitle = {Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering},
pages = {749–756},
numpages = {8},
keywords = {DSL for test automation, keyword-driven test automation, Test automation, process-driven test automation, Helsenorge},
location = {Montpellier, France},
series = {ASE 2018}
}

@inproceedings{10.5555/227726.227842,
author = {Kieburtz, Richard B. and McKinney, Laura and Bell, Jeffrey M. and Hook, James and Kotov, Alex and Lewis, Jeffrey and Oliva, Dino P. and Sheard, Tim and Smith, Ira and Walton, Lisa},
title = {A Software Engineering Experiment in Software Component Generation},
year = {1996},
isbn = {0818672463},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {The paper presents results of a software engineering experiment in which a new technology for constructing program generators from domain-specific specification languages has been compared with a reuse technology that employs sets of reusable Ada program templates. Both technologies were applied to a common problem domain, constructing message translation and validation modules for military command, control, communications and information systems (C/sup 3/I). The experiment employed four subjects to conduct trials of use of the two technologies on a common set of test examples. The experiment was conducted with personnel supplied and supervised by an independent contractor. Test cases consisted of message specifications taken from Air Force C/sup 3/I systems. The main results are that greater productivity was achieved and fewer error were introduced when subjects used the program generator than when they used Ada templates to implement software modules from sets of specifications. The differences in the average performance of the subjects are statistically significant at confidence levels exceeding 99 percent.},
booktitle = {Proceedings of the 18th International Conference on Software Engineering},
pages = {542–552},
numpages = {11},
keywords = {reliability, software component generation, usability, flexibility, productivity},
location = {Berlin, Germany},
series = {ICSE '96}
}

