@inproceedings{20110113552572 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {An integrated domain specific language for post-processing and visualizing electrophysiological signals in Java},
journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
author = {Strasser, T. and Peters, T. and Jagle, H. and Zrenner, E. and Wilke, R.},
year = {2010},
pages = {4687 - 4690},
abstract = {Electrophysiology of vision - especially the electroretinogram (ERG) - is used as a non-invasive way for functional testing of the visual system. The ERG is a combined electrical response generated by neural and non-neuronal cells in the retina in response to light stimulation. This response can be recorded and used for diagnosis of numerous disorders. For both clinical practice and clinical trials it is important to process those signals in an accurate and fast way and to provide the results as structured, consistent reports. Therefore, we developed a freely available and open-source framework in Java (http://www.eye.uni-tuebingen.de/projectlidsI4sigproc). The framework is focused on an easy integration with existing applications. By leveraging well-established software patterns like pipes-and-filters and fluent interfaces as well as by designing the application programming interfaces (API) as an integrated domain specific language (DSL) the overall framework provides a smooth learning curve. Additionally, it already contains several processing methods and visualization features and can be extended easily by implementing the provided interfaces. In this way, not only can new processing methods be added but the framework can also be adopted for other areas of signal processing. This article describes in detail the structure and implementation of the framework and demonstrate its application through the software package used in clinical practice and clinical trials at the University Eye Hospital Tuebingen one of the largest departments in the field of visual electrophysiology in Europe. &copy; 2010 IEEE.<br/>},
key = {Application programming interfaces (API)},
keywords = {Application programs;Visual languages;Open source software;Signal processing;Java programming language;Electrophysiology;Neurology;Problem oriented languages;Processing;},
note = {Clinical practices;Domain specific languages;Electrical response;Electroretinograms;Functional testing;Open source frameworks;Processing method;Software patterns;},
URL = {http://dx.doi.org/10.1109/IEMBS.2010.5626417},
} 


@inproceedings{20103513188582 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {A C++-embedded domain-specific language for programming the MORA soft processor array},
journal = {Proceedings of the International Conference on Application-Specific Systems, Architectures and Processors},
author = {Vanderbauwhede, W. and Margala, M. and Chalamalasetti, S.R. and Purohit, S.},
year = {2010},
pages = {141 - 148},
issn = {10636862},
address = {Rennes, France},
abstract = {MORA is a novel platform for high-level FPGA programming of streaming vector and matrix operations, aimed at multimedia applications. It consists of soft array of pipelined low-complexity SIMD processors-in-memory (PIM). We present a Domain-Specific Language (DSL) for high-level programming of the MORA soft processor array. The DSL is embedded in C++, providing designers with a familiar language framework and the ability to compile designs using a standard compiler for functional testing before generating the FPGA bitstream using the MORA toolchain. The paper discusses the MORA-C++ DSL and the compilation route into the assembly for the MORA machine and provides examples to illustrate the programming model and performance. &copy; 2010 IEEE.<br/>},
key = {C++ (programming language)},
keywords = {Ability testing;Program compilers;Problem oriented languages;Field programmable gate arrays (FPGA);Pipeline processing systems;Digital subscriber lines;Graphical user interfaces;},
note = {Domain specific languages;Embedded domain specific languages;High-level programming;Multimedia applications;Multimedia processing;Programming models;Reconfigurable processors;Soft processors;},
URL = {http://dx.doi.org/10.1109/ASAP.2010.5540750},
} 


@inproceedings{20154001337207 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Legend: An agile DSL toolset for web acceptance testing},
journal = {2014 International Symposium on Software Testing and Analysis, ISSTA 2014 - Proceedings},
author = {King, Tariq M. and Nunez, Gabriel and Santiago, Dionny and Cando, Adam and Mack, Cody},
year = {2014},
pages = {409 - 412},
address = {San Jose, CA, United states},
abstract = {<div data-language="eng" data-ev-field="abstract">Agile development emphasizes collaborations among customers, business analysts, domain experts, developers, and testers. However, the large scale and rapid pace of many agile projects presents challenges during testing activities. Large sets of test artifacts must be comprehensible and available to various stakeholders, traceable to requirements, and easily maintainable as the software evolves. In this paper we describe Legend, a toolset that leverages domain-specific language to streamline functional testing in agile projects. Some key features of the toolset include test template generation from user stories, model-based automation, test inventory synchronization, and centralized test tagging.<br/></div> Copyright 2014 ACM.},
key = {Software testing},
keywords = {Problem oriented languages;Digital subscriber lines;Acceptance tests;Graphical user interfaces;},
note = {Acceptance testing;Agile development;Behavior-driven development;Business analysts;Domain specific languages;Functional testing;Model-based OPC;Test Automation;},
URL = {http://dx.doi.org/10.1145/2610384.2628048},
} 


@inproceedings{20165203173126 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Automated regression testing of BPMN 2.0 processes a capture and replay framework for continuous delivery},
journal = {GPCE 2016 - Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2016},
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
year = {2016},
pages = {178 - 189},
address = {Amsterdam, Netherlands},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired sideeffects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-Tolerance. The results, indicating 3:9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.<br/> &copy;2016 ACM.},
key = {Regression analysis},
keywords = {Computer software selection and evaluation;Automation;Modeling languages;Web services;Fault tolerance;Software testing;Problem oriented languages;},
note = {BPMN 2.0;Business process execution;JBPM;Node mocking;Performance overhead;Regression testing;Test Automation;},
URL = {http://dx.doi.org/10.1145/2993236.2993257},
} 


@article{20201908616657 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Automated regression testing of BPMN 2.0 processes: A capture and replay framework for continuous delivery},
journal = {ACM SIGPLAN Notices},
author = {Makki, Majid and Van Landuyt, Dimitri and Joosen, Wouter},
volume = {52},
number = {3},
year = {2016},
pages = {178 - 189},
issn = {15232867},
abstract = {Regression testing is a form of software quality assurance (QA) that involves comparing the behavior of a newer version of a software artifact to its earlier correct behavior, and signaling the QA engineer when deviations are detected. Given the large potential in automated generation and execution of regression test cases for business process models in the context of running systems, powerful tools are required to make this practically feasible, more specifically to limit the potential impact on production systems, and to reduce the manual effort required from QA engineers. In this paper, we present a regression testing automation framework that implements the capture & replay paradigm in the context of BPMN 2.0, a domain-specific language for modeling and executing business processes. The framework employs parallelization techniques and efficient communication patterns to reduce the performance overhead of capturing. Based on inputs from the QA engineer, it manipulates the BPMN2 model before executing tests for isolating the latter from external dependencies (e.g. human actors or expensive web services) and for avoiding undesired side-effects. Finally, it performs a regression detection algorithm and reports the results to the QA engineer. We have implemented our framework on top of a BPMN2-compliant execution engine, namely jBPM, and performed functional validations and evaluations of its performance and fault-tolerance. The results, indicating 3.9% average capturing performance overhead, demonstrate that the implemented framework can be the foundation of a practical regression testing tool for BPMN 2.0, and a key enabler for continuous delivery of business process-driven applications and services.<br/> &copy; 2016 ACM.},
key = {Regression analysis},
keywords = {Automation;Fault tolerance;Modeling languages;Software testing;Computer software selection and evaluation;Problem oriented languages;Engineers;Web services;},
note = {Automated generation;Automated regression testing;Business process model;Detection algorithm;Domain specific languages;Efficient communications;Functional validation;Parallelization techniques;},
URL = {http://dx.doi.org/10.1145/2993236.2993257},
} 


@inproceedings{20180504691895 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Evaluation of an integrated tool environment for experimentation in DSL engineering},
journal = {Lecture Notes in Business Information Processing},
author = {Haser, Florian and Felderer, Michael and Breu, Ruth},
volume = {302},
year = {2018},
pages = {147 - 168},
issn = {18651348},
address = {Vienna, Austria},
abstract = {Domain specific languages (DSL) are a popular means for providing customized solutions to a certain problem domain. So far, however, language workbenches lack sufficient built-in features in providing decision support when it comes to language design and improvement. Controlled experiments can provide data-driven decision support for both, researchers and language engineers, for comparing different languages or language features. This paper provides an evaluation of an integrated end-to-end tool environment for performing controlled experiments in DSL engineering. The experimentation environment is presented by a running example from engineering domain specific languages for acceptance testing. The tool is built on and integrated into the Meta Programming System (MPS) language workbench. For each step of an experiment the language engineer is supported by suitable DSLs and tools all within the MPS platform. The evaluation, from the viewpoint of the experiments subject, is based on the technology acceptance model (TAM). Results reveal that the subjects found the DSL experimentation environment intuitive and easy to use.<br/> &copy; Springer International Publishing AG 2018.},
key = {Acceptance tests},
keywords = {Software engineering;Digital subscriber lines;Problem oriented languages;Decision support systems;},
note = {Domain specific languages;Empirical Software Engineering;Experimentation;Language engineering;Meta Programming;Model based software engineering;},
URL = {http://dx.doi.org/10.1007/978-3-319-71440-0_9},
} 


@inproceedings{20124415610620 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Application of build-in self test in functional test of DSL},
journal = {IPC APEX EXPO 2012},
author = {Gu, YaJun and Qin, Ye and Wang, ZhiJun and Wei, David and Ho, Andrew and Chen, Stephen and Feng, Zhen and Kurwa, Murad},
volume = {2},
year = {2012},
pages = {945 - 959},
address = {San Diego, CA, United states},
} 


@inproceedings{20124415610585 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Application of build-in self test in functional test of DSL},
journal = {IPC APEX EXPO 2012},
author = {Gu, YaJun and Qin, Ye and Wang, ZhiJun and Wei, David and Ho, Andrew and Chen, Stephen and Feng, Zhen and Kurwa, Murad},
volume = {1},
year = {2012},
pages = {233 - 234},
address = {San Diego, CA, United states},
} 


@article{20143600043933 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Model transformations for migrating legacy deployment models in the automotive industry},
journal = {Software and Systems Modeling},
author = {Selim, Gehan M. K. and Wang, Shige and Cordy, James R. and Dingel, Juergen},
volume = {14},
number = {1},
year = {2015},
pages = {365 - 381},
issn = {16191366},
abstract = {<div data-language="eng" data-ev-field="abstract">Many companies in the automotive industry have adopted model-driven development in their vehicle software development. As a major automotive company, General Motors (GM) has been using a custom-built, domain-specific modeling language, implemented as an internal proprietary metamodel, to meet the modeling needs in its control software development. Since AUTomotive Open System ARchitecture (AUTOSAR) has been developed as a standard to ease the process of integrating components provided by different suppliers and manufacturers, there has been a growing demand to migrate these GM-specific, legacy models to AUTOSAR models. Given that AUTOSAR defines its own metamodel for various system artifacts in automotive software development, we explore applying model transformations to address the challenges in migrating GM-specific, legacy models to their AUTOSAR equivalents. As a case study, we have built and validated a model transformation using the MDWorkbench tool, the Atlas Transformation Language, and the Metamodel Coverage Checker tool. This paper reports on the case study, makes observations based on our experience to assist in the development of similar types of transformations, and provides recommendations for further research.<br/></div> &copy; 2013, Springer-Verlag Berlin Heidelberg.},
key = {Automotive industry},
keywords = {Specification languages;Open systems;Software design;Embedded systems;Open source software;Black-box testing;Modeling languages;},
note = {Automotive control softwares;AutoSAR;Model transformation;Model-driven development;Transformation languages;},
URL = {http://dx.doi.org/10.1007/s10270-013-0365-1},
} 


@article{20164502986281 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based testing for building reliable realtime interactive music systems},
journal = {Science of Computer Programming},
author = {Poncelet, Clement and Jacquemard, Florent},
volume = {132},
year = {2016},
pages = {143 - 172},
issn = {01676423},
abstract = {The role of an Interactive Music System (IMS) is to accompany musicians during live performances, acting like a real musician. It must react in realtime to audio signals from musicians, according to a timed high-level requirement called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not much addressed by the computer music community. We present the application of Model-Based Testing techniques and tools to a state-of-the-art IMS, including in particular: offline and on-the-fly approaches for the generation of relevant input data for testing (including timing values), with coverage criteria, the computation of the corresponding expected output, according to the semantics of a given mixed score, the black-box execution of the test data on the System Under Test and the production of a verdict. Our method is based on formal models in a dedicated intermediate representation, compiled directly from mixed scores (high-level requirements), and either passed, to the model-checker Uppaal (after conversion to Timed Automata) in the offline approach, or executed by a virtual machine in the online approach. Our fully automatic framework has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS.<br/> &copy; 2016 Elsevier B.V.},
key = {Semantics},
keywords = {Automata theory;Black-box testing;Audio acoustics;Problem oriented languages;Computer music;Model checking;},
note = {Coverage criteria;Domain specific languages;Interactive music systems;Intermediate representations;Model based testing;Off-line approaches;Temporal reliability;Timed Automata;},
URL = {http://dx.doi.org/10.1016/j.scico.2016.08.002},
} 


@inproceedings{20224613122914 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Automatic test amplification for executable models},
journal = {Proceedings - 25th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems, MODELS 2022},
author = {Khorram, Faezeh and Bousse, Erwan and Mottu, Jean-Marie and Sunye, Gerson and Gomez-Abajo, Pablo and Canizares, Pablo C. and Guerra, Esther and De Lara, Juan},
year = {2022},
pages = {109 - 120},
address = {Montreal, Canada},
abstract = {<div data-language="eng" data-ev-field="abstract">Behavioral models are important assets that must be thoroughly verified early in the design process. This can be achieved with manually-written test cases that embed carefully hand-picked domain-specific input data. However, such test cases may not always reach the desired level of quality, such as high coverage or being able to localize faults efficiently. Test amplification is an interesting emergent approach to improve a test suite by automatically generating new test cases out of existing manually-written ones. Yet, while ad-hoc test amplification solutions have been proposed for a few programming languages, no solution currently exists for amplifying the test cases of behavioral models. In this paper, we fill this gap with an automated and generic approach. Given an executable DSL, a conforming behavioral model, and an existing test suite, our approach generates new regression test cases in three steps: (i) generating new test inputs by applying a set of generic modifiers on the existing test inputs; (ii) running the model under test with new inputs and generating assertions from the execution traces; and (iii) selecting the new test cases that increase the mutation score. We provide tool support for the approach atop the Eclipse GEMOC Studio1 and show its applicability in an empirical study. In the experiment, we applied the approach to 71 test suites written for models conforming to two different DSLs, and for 67 of the 71 cases, it successfully improved the mutation score between 3.17% and 54.11% depending on the initial setup.<br/></div> &copy; 2022 ACM.},
key = {Software testing},
keywords = {Behavioral research;Digital subscriber lines;},
note = {Behavioral model;Design-process;Executable DSL;Executable modeling;Executables;Mutation score;Regression testing;Test amplifications;Test case;Test inputs;},
URL = {http://dx.doi.org/10.1145/3550355.3552451},
} 


@inproceedings{20160501861464 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Model based testing of an interactive music system},
journal = {Proceedings of the ACM Symposium on Applied Computing},
author = {Poncelet, Clement and Jacquemard, Florent},
volume = {13-17-April-2015},
year = {2015},
pages = {1759 - 1764},
address = {Salamanca, Spain},
abstract = {The role of an interactive music system (IMS) is to accompany musicians during live performances, like a real musician. It reacts in realtime to audio signals from musicians, according to a timed specification called mixed score, written in a domain specific language. Such goals imply strong requirements of temporal reliability and robustness to unforeseen errors in input, yet not so much studied in the computer music community. We present the application of model-based testing techniques and tools to a state-of-the-art IMS, including the following tasks: generation of relevant input data for testing (including timing values) following coverage criteria, computation of the corresponding expected output, according to the semantics of a given mixed score, black-box execution of the test data and verdict. Our method is based on formal models compiled directly from mixed scores, and passed, after conversion to timed automata, to the model-checker Uppaal. This fully automatic approach has been applied to real mixed scores used in concerts and the results obtained have permitted to identify bugs in the target IMS.<br/> Copyright 2015 ACM.},
key = {Semantics},
keywords = {Problem oriented languages;Model checking;Automata theory;Computer music;Black-box testing;Graphical user interfaces;},
note = {Automatic approaches;Coverage criteria;Domain specific languages;Interactive music systems;Model based testing;State of the art;Temporal reliability;Timed Automata;},
URL = {http://dx.doi.org/10.1145/2695664.2695804},
} 


@inproceedings{20204209341603 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Model-based testing in agile projects: An approach based on domain-specific languages},
journal = {23rd Iberoamerican Conference on Software Engineering, CIbSE 2020},
author = {Zanin, Aline and Zorzo, Avelino Fracisco and Nunes, Henry Cabral},
year = {2020},
address = {Curitiba, Brazil},
abstract = {Model-Based Testing (MBT) can bring several benefits to software quality. However, generally, MBT is applied in traditional software development lifecycle models, with few studies exploring its application in agile software development context. Hence, usually, agile development teams (AT) do not benefit from the advantages that the MBT technique provides, for example, reuse of artifacts and traceability between requirements and test artifacts. Thus, this article presents an approach for applying MBT in agile software development teams. This approach is based on the use of a semi-natural language to write scenarios for the automatic generation of models and test scripts. To exemplify the application of this approach, we also present a Domain-Specific Language (DSL) called Aquila, in which new functional test related keywords are added to the Gherkin DSL. We also present, based on a literature review, the majors challenges and difficulties of applying MBT in AT. To validate the proposed approach a Focus Group study was used.<br/> &copy; CIbSE 2020.},
key = {Software testing},
keywords = {Application programs;Model checking;Life cycle;Computer software selection and evaluation;Software design;Digital subscriber lines;Problem oriented languages;},
note = {Agile development;Agile software development;Automatic Generation;Domain specific languages;Focus group studies;Literature reviews;Model based testing;Software development life cycle;},
} 


@inproceedings{20183905860278 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {A process for evidence-based engineering of domain-specific languages},
journal = {ACM International Conference Proceeding Series},
author = {Felderer, Michael and Jeschko, Fabian},
year = {2018},
pages = {SIGNAL; Software Innovation - },
address = {Christchurch, New zealand},
abstract = {Domain-specific languages (DSLs) are mainly designed ad-hoc and gut feeling resulting in languages that are often not well suited for their users and engineers. In this paper we develop a process for evidence-based language engineering to design domain-specific languages based on empirical evidence to support decision in language engineering. The developed process comprises an iterative execution of the phases DSL engineering, issue identification, data collection and evidence appraisal. We exemplify the concept by designing a DSL for Gherkin, a language test-driven acceptance testing in Xtext. The required evidence is derived by mining and analyzing all GitHub projects until July 1, 2017 that apply Gherkin.<br/> &copy; 2018 Association for Computing Machinery.},
key = {Acceptance tests},
keywords = {Problem oriented languages;Software engineering;Digital subscriber lines;},
note = {Acceptance testing;Data collection;Domain specific languages;Empirical research;Evidence Based Software Engineering;Issue identifications;Language engineering;Repository mining;},
URL = {http://dx.doi.org/10.1145/3210459.3210479},
} 


@inproceedings{20113714315180 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Using Haskell to script combinatoric testing of web services},
journal = {Proceedings of the 6th Iberian Conference on Information Systems and Technologies, CISTI 2011},
author = {Prasetya, I.S.W.B. and Amorim, J. and Vos, T.E.J. and Baars, A.},
year = {2011},
abstract = {The Classification Tree Method (CTM) is a popular approach in functional testing as it allows the testers to systematically partition the input domain of an SUT, and specifies the combinations they want. We have implemented the approach as a small domain specific language (DSL) embedded in the functional language Haskell. Such an embedding leads to clean syntax and moreover we can natively access Haskell's full features. This paper will explain the approach, and how it is applied for testing Web Services. &copy; 2011 AISTI.<br/>},
key = {Websites},
keywords = {Web services;Combinatorial mathematics;Problem oriented languages;},
note = {Automated testing;Classification tree method;Domain specific languages;Functional languages;Functional testing;Haskell;},
} 


@inproceedings{20172703897368 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {ACM International Conference Proceeding Series},
journal = {ACM International Conference Proceeding Series},
volume = {Part F128404},
year = {2016},
pages = {City of Lugano; Hasler Foundation; Oracle Labs; Universita della Svizzera Italiana, Faculty of Informatics - },
address = {Lugano, Switzerland},
abstract = {The proceedings contain 18 papers. The topics discussed include: deeply reifying running code for constructing a domain-specific language; a distributed selectors runtime system for Java applications; efficient memory traces with full pointer information; extraction-based regression test selection; inference and checking of object immutability; integrating asynchronous task parallelism and data-centric atomicity; JCrypt: towards computation over encrypted data; multi-tier data synchronization based on an optimized concurrent linked-list; preexistence and concrete type analysis in the context of multiple inheritance; and prioritizing regression tests for desktop and web-applications based on the execution frequency of modified code.<br/>},
} 


@inproceedings{20123115287320 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Declarative automated test},
journal = {2012 7th International Workshop on Automation of Software Test, AST 2012 - Proceedings},
author = {Hallenberg, Niels and Carlsen, Philip Lykke},
year = {2012},
pages = {96 - 102},
address = {Zurich, Switzerland},
abstract = {Automated tests at the business level can be expensive to develop and maintain. One common approach is to have a domain expert instruct a QA developer to implement what she would do manually in the application. Though there exist record-replay tools specifically developed for this, these tend to scale poorly for more complicated test scenarios. We present a different solution: An Embedded Domain Specific Language (EDSL) in F#, containing the means to model the user interface, and the various manipulations of it. We hope that this DSL will bridge the gap between the business domain and technical domain of applications to such a degree that domain experts may be able to construct automatic tests without depending on QA developers, and that these tests will prove more maintainable. &copy; 2012 IEEE.<br/>},
key = {User interfaces},
keywords = {Software testing;Automation;Problem oriented languages;},
note = {Automated test;Automated testing;Business domain;Domain experts;Domain specific languages;Embedded domain specific languages;Functional testing;Record-replay;},
URL = {http://dx.doi.org/10.1109/IWAST.2012.6228998},
} 


@inproceedings{20150400440526 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Test process improvement with documentation driven integration testing},
journal = {Proceedings - 2014 9th International Conference on the Quality of Information and Communications Technology, QUATIC 2014},
author = {Haser, Florian and Felderer, Michael and Breu, Ruth},
year = {2014},
pages = {156 - 161},
address = {Guimaraes, Portugal},
abstract = {Improving the maturity of the test process in an organization, especially but not limited to integration testing, involves obstacles and risks, such as the additional work overhead of the new process. In addition, integration testing descriptions are often too technical not addressing the language needs of the domain. In research cooperations with companies from the insurance and banking domain it turned out that test descriptions and reports are one of the most useful testing artifacts, while doing adhoc testing. This paper presents a bottom up testing approach, which first helps the integration tester in producing a semi-formal test description and report, up to be an enabler for automatic model-based testing in the very end. The presented approach is based on a textual domain specific language that is able to evolve over time. This is done by analyzing the test descriptions and reports automatically with machine learning techniques as well as manually by integration testers. Often recurring test steps or used components are integrated into the test language, making it specially tailored for a specific organization. For each test step implementations can be attached, preparing it for the next iteration. In this paper the methodology and architecture of our integration testing approach are presented together with the underlying language concepts.<br/> &copy; 2014 IEEE.},
key = {Integration testing},
keywords = {Process engineering;Iterative methods;Integration;Learning systems;Model checking;Problem oriented languages;},
note = {Automatic modeling;Domain specific languages;Machine learning techniques;Model-based integrations;Regression testing;Research cooperation;Test process;Underlying language;},
URL = {http://dx.doi.org/10.1109/QUATIC.2014.29},
} 


@inproceedings{20181805112947 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
volume = {2017-December},
year = {2017},
issn = {15301362},
address = {Nanjing, Jiangsu, China},
abstract = {The proceedings contain 93 papers. The topics discussed include: extracting traceability between predicates in event-B refinement; an improved approach to traceability recovery based on word embeddings; application of LSSVM and SMOTE on seven open source projects for predicting refactoring at class level; detecting full initialization points of objects to support code refactorings; a cloud-based trust evaluation scheme using a vehicular social network environment; Noff: a novel extendible parallel library for high-performance network traffic monitoring; a reusable framework for modeling and verifying in-vehicle networking systems in the presence of CAN and FlexRay; cost-effective regression testing using bloom filters in continuous integration development environments; correlation between the frequent use of gang-of-four design patterns and structural complexity; method level text summarization for java code using nano-patterns; flexible components for development of embedded systems with GPUs; Exniffer: learning to prioritize crashes by assessing the exploitability from memory dump; modeling and verifying identity authentication security of HDFS using CSP; a goal-driven framework in support of knowledge management; extracting insights from the topology of the JavaScript package ecosystem; improving bug localization with an enhanced convolutional neural network; mining handover process in open source development: an exploratory study; an analysis method of safety requirements for automotive software systems; and domain-specific language facilitates scheduling in model checking.<br/>},
} 


@article{2000505390853 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Programmable DSP-based DSL chipsets streamline system testing},
journal = {EE: Evaluation Engineering},
author = {Vogel, Erich and Halbach, Robert and Sheppard, Ben},
volume = {39},
number = {10},
year = {2000},
pages = {4 pp - 4 pp},
issn = {01490370},
abstract = {The streamline testing of programmable digital signal processing (DSP)-based digital subscriber line (DSL) was discussed. The programmable DSP-based solutions were tested by performing signal analysis and generation functions in software. The programmable solution allowed manufacturing tests to be customized to individual system requirements. The manufacturing verification process for DSL modems was completed in three stages of in-circuit, parametric and functional testing.},
key = {Microprocessor chips},
keywords = {Costs;Digital signal processing;Integrated circuit testing;Microprogramming;Modems;},
note = {Digital subscriber lines (DSL);In-circuit testing (ICT);},
} 


@inproceedings{20124815732189 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Computer Applications for Software Engineering, Disaster Recovery, and Business Continuity - International Conferences, ASEA and DRBC 2012, Held in Conjunction with GST 2012, Proceedings},
journal = {Communications in Computer and Information Science},
volume = {340 CCIS},
year = {2012},
issn = {18650929},
address = {Jeju Island, Korea, Republic of},
abstract = {The proceedings contain 62 papers. The topics discussed include: impact on realistic mobility model for aircraft ad hoc networks; technology network model using bipartite social network analysis; mobile application development using component features and inheritance; view, level and fragment: commonalities in 'Architecture 101' and software modelling; highly analysable, reusable, and realisable architectural designs with XCD; ARSL: a domain specific language for aircraft separation minima determination; regression testing of object-oriented software: a technique based on use cases and associated tool; development of an instant meeting Android application using Wi-Fi direct APIs; developer support for understanding preprocessor macro expansions; towards building method level maintainability models based on expert evaluations; and a study on the improved stability of inverter through history management of semiconductor elements for power supply.},
} 


@inproceedings{20123015276547 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Modelling Foundations and Applications - 8th European Conference, ECMFA 2012, Proceedings},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {7349 LNCS},
year = {2012},
issn = {03029743},
address = {Kgs. Lyngby, Denmark},
abstract = {The proceedings contain 30 papers. The topics discussed include: executable UML: from multi-domain to multi-core; models meeting automotive design challenges; a commutative model composition operator to support software adaptation; comparative study of model-based and multi-domain system engineering approaches for industrial settings; strengthening SAT-based validation of UML/OCL models by representing collections as relations; model interchange testing: a process and a case study; an internal domain-specific language for constructing OPC UA queries and event filters; combining UML sequence and state machine diagrams for data-flow based integration testing; model transformations for migrating legacy models: an industrial case study; derived features for EMF by integrating advanced model queries; a lightweight approach for managing XML documents with MDE languages; and bridging the gap between requirements and aspect state machines to support non-functional testing: industrial case studies.},
} 


@article{20194207535580 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {TOWARD A UNIFIED ENGLISH-LIKE REPRESENTATION of SEMANTIC MODELS, DATA, and GRAPH PATTERNS for SUBJECT MATTER EXPERTS},
journal = {International Journal of Semantic Computing},
author = {Crapo, Andrew and Moitra, Abha},
volume = {7},
number = {3},
year = {2013},
pages = {215 - 236},
issn = {1793351X},
abstract = {The Semantic Application Design Language (SADL) combines advances in standardized declarative modeling languages based on formal logic with advances in domain-specific language (DSL) development environments to create a controlled-English language that translates directly into the Web Ontology Language (OWL), the SPARQL graph query language, and a compatible if/then rule language. Models in the SADL language can be authored, tested, and maintained in an Eclipse-based integrated development environment (IDE). This environment offers semantic highlighting, statement completion, expression templates, hyperlinking of concepts to their definition, model validation, automatic error correction, and other advanced authoring features to enhance the ease and productivity of the modeling environment. In addition, the SADL language offers the ability to build in validation tests and test suites that can be used for regression testing. Through common Eclipse functionality, the models can be easily placed under source code control, versioned, and managed throughout the life of the model. Differences between versions can be compared side-by-side. Finally, the SADL-IDE offers an explanation capability that is useful in understanding what was inferred by the reasoner/rule engine and why those conclusions were reached. Perhaps more importantly, explanation is available of why an expected inference failed to occur. The objective of the language and the IDE is to enable domain experts to play a more active and productive role in capturing their knowledge and making it available as computable artifacts useful for automation where appropriate and for decision support systems in applications that benefit from a collaborative human-computer approach. SADL is built entirely on open source code and most of SADL is itself released to open source. This paper explores the concepts behind the language and provides details and examples of the authoring and model lifecycle support facilities.<br/> &copy; 2013 World Scientific Publishing Company.},
key = {Semantics},
keywords = {Artificial intelligence;Markup languages;Error correction;Modeling languages;Ontology;Context free languages;Human computer interaction;Open source software;Open systems;Query languages;Birds;Decision support systems;Integrodifferential equations;Problem oriented languages;Visual languages;},
note = {Controlled English;Development environment;Domain specific languages;Graph patterns;Integrated development environment;Semantic Model;Subject matter experts;Web ontology language;},
URL = {http://dx.doi.org/10.1142/S1793351X13500025},
} 


@inproceedings{20202508836574 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {A Universal Automated Test Solution for Trunking Communication System},
journal = {Proceedings - 2020 International Conference on Computer Engineering and Application, ICCEA 2020},
author = {Liu, Huabin},
year = {2020},
pages = {47 - 51},
address = {Guangzhou, China},
abstract = {In order to improve the portability of the automated test of the trunking communication system, this paper proposed a universal automated test solution for the trunking communication system. It's based on the general architecture design of the trunking communication system, providing a replaceable communication protocol codec module. With the DSL-defined test script language describing the test cases, and efficient scheduling schemes for the test task, the automated functional test and performance test of the trunking communication system are realized. Theoretical analysis and experimental results show that the minimum load test task scheduling scheme based on user operation load prediction has lower response time and lower load balancing effect compared with the traditional static task scheduling scheme.<br/> &copy; 2020 IEEE.},
key = {Network architecture},
keywords = {Load testing;Testing;Scheduling algorithms;Multitasking;Automation;},
note = {Automated test solutions;Efficient scheduling;General architectures;Load predictions;Performance tests;Static task scheduling;Test script languages;Trunking communication systems;},
URL = {http://dx.doi.org/10.1109/ICCEA50009.2020.00017},
} 


@article{20063810118906 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {HOTTest: A model-based test design technique for enhanced testing of domain-specific applications},
journal = {ACM Transactions on Software Engineering and Methodology},
author = {Sinha, Avik and Smidts, Carol},
volume = {15},
number = {3},
year = {2006},
pages = {242 - 278},
issn = {1049331X},
abstract = {Model-based testing is an effective black-box test generation technique for applications. Existing model-based testing techniques, however, fail to capture implicit domain-specific properties, as they overtly rely on software artifacts such as design documents, requirement specifications, etc., for completeness of the test model. This article presents a technique, HOTTest, which uses a strongly typed domain-specific language to model the system under test. This allows extraction of type-related system invariants, which can be related to various domain-specific properties of the application. Thus, using HOTTest, it is possible to automatically extract and embed domain-specific requirements into the test models. In this article we describe HOTTest, its principles and methodology, and how it is possible to relate domain-specific properties to specific type constraints. HOTTest is described using the example of HaskellDB, which is a Haskell-based embedded domain-specific language for relational databases. We present an example application of the technique and compare the results to some other commonly used Model-based test automation techniques like ASML-based testing, UML-based testing, and EFSM-based testing. &copy; 2006 ACM.},
key = {Software engineering},
keywords = {Automation;Computer programming languages;Database systems;Embedded systems;Mathematical models;},
note = {Database-specific test case generation;Domain-specific languages;Domain-specific testing;HaskellDB;Haskells;Model-based testing;Test case generation;Test generation tools;},
URL = {http://dx.doi.org/10.1145/1151695.1151697},
} 


@article{20164102895331 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Is business domain language support beneficial for creating test case specifications: A controlled experiment},
journal = {Information and Software Technology},
author = {Haser, Florian and Felderer, Michael and Breu, Ruth},
volume = {79},
year = {2016},
pages = {52 - 62},
issn = {09505849},
abstract = {Context: Behavior Driven Development (BDD), widely used in modern software development, enables easy creation of acceptance test case specifications and serves as a communication basis between business- and technical-oriented stakeholders. BDD is largely facilitated through simple domain specific languages (DSL) and usually restricted to technical test domain concepts. Integrating business domain concepts to implement a ubiquitous language for all members of the development team is an appealing test language improvement issue. But the integration of business domain concepts into BDD toolkits has so far not been investigated. Objective: The objective of the study presented in this paper is to examine whether supporting the ubiquitous language features inside a DSL, by extending a DSL with business domain concepts, is beneficial over using a DSL without those concepts. In the context of the study, benefit is measured in terms of perceived quality, creation time and length of the created test case specifications. In addition, we analyze if participants feel supported when using predefined business domain concepts. Method: We investigate the creation of test case specifications, similar to BDD, in a controlled student experiment performed with graduate students based on a novel platform for DSL experimentation. The experiment was carried out by two groups, each solving a similar comparable test case, one with the simple DSL, the other one with the DSL that includes business domain concepts. A crossover design was chosen for evaluating the perceived quality of the resulting specifications. Results: Our experiment indicates that a business domain aware language allows significant faster creation of documents without lowering the perceived quality. Subjects felt better supported by the DSL with business concepts. Conclusion: Based on our findings we propose that existing BDD toolkits could be further improved by integrating business domain concepts.<br/> &copy; 2016 Elsevier B.V.},
key = {Acceptance tests},
keywords = {Digital subscriber lines;Graphical user interfaces;Students;Problem oriented languages;Software design;Software testing;Specifications;},
note = {Behavior driven development;Controlled experiment;Development teams;Domain specific languages;Graduate students;Language features;Student experiments;Test case specifications;},
URL = {http://dx.doi.org/10.1016/j.infsof.2016.07.001},
} 


@inproceedings{20123515370190 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Proceedings of EuroPLoP 2009 - 14th Annual European Conference on Pattern Languages of Programming},
journal = {Proceedings of EuroPLoP 2009 - 14th Annual European Conference on Pattern Languages of Programming},
year = {2009},
address = {Irsee, Germany},
abstract = {The proceedings contain 32 papers. The topics discussed include: enterprise architecture management patterns for enterprise architecture visioning; roles in a software project; applied pattern for strategy management for technology entrepreneurship and innovation MSc program; performance of open source projects; the role of analysis patterns in systems analysis; applying architectural patterns for parallel programming: solving the one-dimensional heat equation; towards formalized adaptation patterns for adaptive interactive systems; a pattern driven approach against architectural knowledge vaporization; reusable architectural decisions for DSL design: foundational decisions in DSL projects; a pattern vocabulary for project distribution; business patterns for knowledge audit implementation; applying distributed development patterns; and a pattern language of black-box test design for reactive software systems.},
} 


@inproceedings{20163002635787 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {16th International Symposium on Trends in Functional Programming, TFP 2015},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
volume = {9547},
year = {2016},
pages = {1 - 156},
issn = {03029743},
address = {Sophia Antipolis, France},
abstract = {The proceedings contain 8 papers. The special focus in this conference is on Trends in Functional Programming. The topics include: lightweight higher-order rewriting in haskell; towards a theory of reach; functional testing of java programs; type class instances for type-level lambdas in haskell; on the role of slicing in functional data-flow programming; a shallow embedded type safe extendable DSL for the arduino and programmable signatures and termination proofs for recursive functions in FoCaLiZe.},
} 


@inproceedings{20124315599205 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Applying industrial-strength testing techniques to critical care medical equipment},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
author = {Woskowski, Christoph},
volume = {7612 LNCS},
year = {2012},
pages = {62 - 73},
issn = {03029743},
address = {Magdeburg, Germany},
abstract = {Hardware and software development of embedded systems interdependently gear into each other. Even more so if the device under development is intended for use in critical care facilities such as intensive care units. Especially in this case, safety measures and risk mitigation techniques are implemented using both hardware and software components. Thus applying hardware and software testing approaches in combination is inevitable as well. The increasing utilization of test domain-specific languages (Test DSLs), code generators and keyword-driven interpreters tends to raise the level of abstraction in test development. This approach aims to enhance productivity by generating executable tests from a non-programming language created for describing test cases. A second goal is to increase coverage by generating tests for as many as possible combinations of input values (black box test) or for all reasonable paths of a program flow (white box test). In combination with hardware-supported signal generation and fault injection this can be a very powerful strategy for testing safety-critical embedded devices. This article introduces an example of this strategy - the usage of a keyword-driven testing technique in cooperation with additional test hardware - in the context of an embedded medical device development, all the while emphasizing the benefit of combining different approaches. It discusses the utilization of commercial off-the-shelf (COTS) testing hardware as well as the application of an in-house developed test box. It also highlights the integration of commercial software - for requirements engineering, test management and continuous integration - with a self-developed testing framework powered by its own keyword-based test DSL. &copy; 2012 Springer-Verlag.<br/>},
key = {Risk assessment},
keywords = {Embedded systems;Integration testing;Safety engineering;Biomedical equipment;Problem oriented languages;Safety testing;Software design;},
note = {Continuous integrations;Domain specific languages;Hardware and software;Hardware and software components;Keyword driven;Medical device development;Medical Devices;Testing hardwares;},
URL = {http://dx.doi.org/10.1007/978-3-642-33678-2_6},
} 


@inproceedings{20223312581697 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Software Engineering 2008 - Fachtagung des GI-Fachbereichs Softwaretechnik},
journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
volume = {P-121},
year = {2008},
issn = {16175468},
address = {Munchen, Germany},
abstract = {<div data-language="eng" data-ev-field="abstract">The proceedings contain 36 papers. The topics discussed include: connecting good theory to good practice: software documentation: a case study; assisting needs driven requirements engineering with the ARIS toolset; eliminating trust from application programs by way of software architecture; towards automatic construction of reusable prediction models for component-based performance engineering; towards effective management of software knowledge exploiting the semantic wiki paradigm; towards a peer-to-peer based global software development environment; combining structural and functional test case generation; Monaco: a DSL approach for programming automation systems; and workshop agile knowledge sharing for distributed software teams.<br/></div>},
} 


@inproceedings{2002477229400 ,
language = {English},
copyright = {Compilation and indexing terms, Copyright 2023 Elsevier Inc.},
copyright = {Compendex},
title = {Plastic ball grid arrays, a qualified packaging technology for high reliability space applications},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
author = {Massey, Mary C. and Parrish, Brian E. and McMullen, William E. and Estes, Thomas J.},
volume = {4828},
year = {2002},
pages = {175 - 180},
issn = {0277786X},
address = {Reno, NV, United states},
abstract = {TRW has qualified a new advanced digital packaging technology for critical space applications; Plastic Ball Grid Array (PBGA) assemblies. This achievement enables use of high I/O, state-of-the-art ASIC designs and promises improved digital subsystem performance at significantly reduced weight and cost. Plastic ball grid array packages accommodating die as large as 17 mm sq. with over 800 I/O are planned on future satellite programs surviving extensive component-level and product-level qualification testing. TRW's space-qualification of laminate-based (organic) area array packaging technology responds to the ever increasing demand for reliable, cost effective, high density interconnect (HDI) solutions while leveraging the commercial standard plastic encapsulated microcircuit (PEM). This paper describes the product line approach used to produce qualification test vehicles representative of proposed flight configurations. TRW's radiation hardened 32-bit processor ASIC was used as an electrically functional test vehicle. The initial research focused on package reliability without hermeticity (RWOH) and solder joint reliability. Test results from a controlled insertion of plastic ball grid array packages on flight-like dual sequential laminated (DSL) boards are presented, where thousands of solder joints are continuously monitored using an inexpensive and highly reliable on-board fault detection circuit. The data demonstrates how this technology can provide a superior integrated circuit (IC) packaging solution over traditional ceramic-based assemblies. Space programs will benefit from aggressive insertion of JEDEC standard PBGA packages to achieve higher performance designs with increased circuit densities, while reducing electronic product's size, weight, power, and cost.},
key = {Electronics packaging},
keywords = {Electric discharges;Integrated circuits;Interconnection networks;Laminates;Printed circuit boards;Reliability;Satellites;Space applications;},
note = {Plastic ball grid arrays (PBGA);},
} 



